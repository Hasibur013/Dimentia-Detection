{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cb175b",
   "metadata": {},
   "source": [
    "# 2. Model Exploration and Hyperparameter Tuning\n",
    "\n",
    "## üìù Overview\n",
    "This notebook is the second step in the dementia prediction pipeline. Its purpose is to:\n",
    "1.  **Load** the pre-cleaned and split data from `1_dataset_analysis.ipynb`.\n",
    "2.  Define a **preprocessing pipeline** to handle scaling and encoding.\n",
    "3.  Use **SMOTE** to address class imbalance in the training data.\n",
    "4.  Train a variety of machine learning models using **GridSearchCV** to find the best hyperparameters for each.\n",
    "5.  **Save** the trained models and their performance results for the final implementation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46073c67",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb398a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af20dae",
   "metadata": {},
   "source": [
    "## ML Model Results Storage Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a95e6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results storage framework loaded successfully!\n",
      "This framework will save results, plots, and models to the 'ModelExploration' directory.\n"
     ]
    }
   ],
   "source": [
    " \n",
    "precision = []\n",
    "roc_auc = []\n",
    "\n",
    "# Function to call for storing the results\n",
    "def store_results(model, config, acc, f1_score, rec, prec, roc):\n",
    "    \"\"\"\n",
    "    Store model performance results.\n",
    "    \"\"\"\n",
    "    ML_Model.append(model)\n",
    "    ML_Config.append(config)\n",
    "    accuracy.append(round(acc, 6))\n",
    "    f1.append(round(f1_score, 6))\n",
    "    recall.append(round(rec, 6))\n",
    "    precision.append(round(prec, 6))\n",
    "    roc_auc.append(round(roc, 6))\n",
    "\n",
    "# Function to display and save results\n",
    "def display_and_save_results(filename_prefix='model_exploration'):\n",
    "    \"\"\"\n",
    "    Create dataframe from results, display, and save to CSV in the 'AnalysisMain/results' directory.\n",
    "    \"\"\"\n",
    "    # Creating the dataframe\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'ROC_AUC': roc_auc,\n",
    "    })\n",
    "    \n",
    "    # Remove duplicates if any\n",
    "    result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Saving the result to a CSV file\n",
    "    save_path = os.path.join(results_dir, f'{filename_prefix}_results.csv')\n",
    "    result.to_csv(save_path, index=False)\n",
    "    print(f\"\\nResults saved to {save_path}\")\n",
    "    \n",
    "    # Sorting the dataframe on F1 Score and Accuracy\n",
    "    sorted_result = result.sort_values(by=['F1 Score', 'Accuracy'], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by F1 Score and Accuracy)\")\n",
    "    print(\"=\"*100)\n",
    "    print(sorted_result.to_string(index=False))\n",
    "    \n",
    "    # Saving the sorted result to a CSV file\n",
    "    sorted_save_path = os.path.join(results_dir, f'sorted_{filename_prefix}_results.csv')\n",
    "    sorted_result.to_csv(sorted_save_path, index=False)\n",
    "    print(f\"\\nSorted results saved to {sorted_save_path}\")\n",
    "    \n",
    "    return result, sorted_result\n",
    "\n",
    "# Function to clear results\n",
    "def clear_results():\n",
    "    \"\"\"Clear all stored results.\"\"\"\n",
    "    global ML_Model, ML_Config, accuracy, f1, recall, precision, roc_auc\n",
    "    ML_Model.clear()\n",
    "    ML_Config.clear()\n",
    "    accuracy.clear()\n",
    "    f1.clear()\n",
    "    recall.clear()\n",
    "    precision.clear()\n",
    "    roc_auc.clear()\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "# Function to plot model comparison\n",
    "def plot_model_comparison(result_df, plot_filename=\"model_performance_comparison.png\"):\n",
    "    \"\"\"\n",
    "    Create visualization comparing model performances and save to 'AnalysisMain/plots'.\n",
    "    \"\"\"\n",
    "    # Convert scores to percentages for plotting\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    plot_df = result_df.copy()\n",
    "    \n",
    "    for col in metrics_cols:\n",
    "        plot_df[col] = plot_df[col] * 100\n",
    "    \n",
    "    # Create subplot for each metric\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_cols):\n",
    "        # Group by model and get mean performance across configurations\n",
    "        model_performance = plot_df.groupby('ML Model')[metric].mean().sort_values(ascending=False)\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        bars = sns.barplot(x=model_performance.index, y=model_performance.values, ax=ax, palette='Blues_r')\n",
    "        \n",
    "        ax.set_title(f'Average {metric}', fontweight='bold')\n",
    "        ax.set_ylabel(f'{metric} (%)')\n",
    "        ax.set_xlabel('')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.grid(axis='y', alpha=0.5)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars.patches:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Hide the last subplot if we have 5 metrics\n",
    "    if len(metrics_cols) < 6:\n",
    "        axes[5].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Model Performance Comparison', fontsize=20, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # Save the plot\n",
    "    save_path = os.path.join(plots_dir, plot_filename)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Comparison plot saved to: {save_path}\")\n",
    "\n",
    "print(\"Model results storage framework loaded successfully!\")\n",
    "print(\"This framework will save results, plots, and models to the 'ModelExploration' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e8ff57",
   "metadata": {},
   "source": [
    "# Define Preprocessing Pipeline\n",
    "\n",
    "Before training the models, we need to create a preprocessing pipeline. This pipeline will handle:\n",
    "1.  **Scaling**: Applying `StandardScaler` to all numerical features to standardize their range.\n",
    "2.  **Encoding**: Applying `OneHotEncoder` to the categorical feature (`M/F`) to convert it into a numerical format.\n",
    "\n",
    "We use a `ColumnTransformer` to apply these different transformations to the correct columns. This ensures that the same steps are consistently applied during both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28c6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from 'processed_data' directory!\n",
      "--------------------------------------------------\n",
      "X_train shape: (647, 12)\n",
      "X_val shape: (162, 12)\n",
      "\n",
      "Training target distribution:\n",
      "Group\n",
      "Nondemented    0.774343\n",
      "Demented       0.225657\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Validation target distribution:\n",
      "Group\n",
      "Nondemented    0.771605\n",
      "Demented       0.228395\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "First 5 rows of X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>Educ</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "      <th>Delay</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>M</td>\n",
       "      <td>84</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1550</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>M</td>\n",
       "      <td>75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1534</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.144</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>F</td>\n",
       "      <td>69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1380</td>\n",
       "      <td>0.809</td>\n",
       "      <td>1.272</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>F</td>\n",
       "      <td>80</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1323</td>\n",
       "      <td>0.738</td>\n",
       "      <td>1.326</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1385</td>\n",
       "      <td>0.819</td>\n",
       "      <td>1.267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    M/F  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  Delay  Visit  MR Delay\n",
       "764   M   84  14.0  2.0  22.0  0.5  1550  0.665  1.132    2.0    2.0     621.0\n",
       "213   M   75   5.0  2.0  29.0  0.0  1534  0.771  1.144    2.0    1.0       0.0\n",
       "382   F   69   4.0  3.0  29.0  0.0  1380  0.809  1.272    2.0    1.0       0.0\n",
       "456   F   80  16.0  2.0  29.0  0.0  1323  0.738  1.326    2.0    2.0     730.0\n",
       "393   F   50  12.0  2.0  30.0  0.0  1385  0.819  1.267    2.0    1.0       0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define the directory where the processed data was saved from the previous notebook\n",
    "processed_data_dir = 'Analysis/processed_data'\n",
    "\n",
    "# Load the training and validation sets\n",
    "X_train = joblib.load(os.path.join(processed_data_dir, 'X_train.joblib'))\n",
    "X_val = joblib.load(os.path.join(processed_data_dir, 'X_val.joblib'))\n",
    "y_train = joblib.load(os.path.join(processed_data_dir, 'y_train.joblib'))\n",
    "y_val = joblib.load(os.path.join(processed_data_dir, 'y_val.joblib'))\n",
    "\n",
    "print(\"Data loaded successfully from 'processed_data' directory!\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"\\nTraining target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nValidation target distribution:\\n{y_val.value_counts(normalize=True)}\")\n",
    "\n",
    "# Display the first few rows of the training data to confirm\n",
    "print(\"\\nFirst 5 rows of X_train:\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c849cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892602bb",
   "metadata": {},
   "source": [
    "### SVM with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b85da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['Age', 'Educ', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'Delay', 'Visit', 'MR Delay']\n",
      "Categorical features: ['M/F']\n",
      "\n",
      "Preprocessed data shape: (647, 13)\n",
      "All features are now numeric: True\n",
      "Results cleared!\n",
      "\n",
      "=== START: SVM Configuration Sweep with Custom Hyperparameters ===\n",
      "\n",
      "‚úì Configuration 1: Preprocessed Data\n",
      "‚úì Configuration 2: Normalized Data (MinMax)\n",
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features: 10\n",
      "‚úì Configuration 3: SelectKBest\n",
      "\n",
      "=== RFECV Feature Selection ===\n",
      "Optimal number of features by RFECV: 3\n",
      "‚úì Configuration 4: RFECV\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components for 90.0% variance: 3\n",
      "‚úì Configuration 5: PCA\n",
      "‚úì Configuration 6: SMOTE + StandardScaler (Pipeline)\n",
      "‚úì Configuration 7: SMOTE + GridSearchCV (Pipeline)\n",
      "\n",
      "================================================================================\n",
      "RUNNING SVM WITH CONFIGURATION-SPECIFIC HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Configuration: Preprocessed Data\n",
      "================================================================================\n",
      "Hyperparameter grid for 'Preprocessed Data':\n",
      "  C: [0.01, 0.1, 1, 10]\n",
      "  gamma: ['scale', 'auto', 0.001, 0.01]\n",
      "  kernel: ['rbf', 'linear']\n",
      "  degree: [2]\n",
      "  coef0: [0.0]\n",
      "Total combinations: 32\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.979907  0.970299 0.955479   0.987354 0.994518\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.995676\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0016\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  C: 10\n",
      "  coef0: 0.0\n",
      "  degree: 2\n",
      "  gamma: scale\n",
      "  kernel: rbf\n",
      "\n",
      "Best CV score: 0.958037\n",
      "\n",
      "================================================================================\n",
      "Configuration: Normalized Data\n",
      "================================================================================\n",
      "Hyperparameter grid for 'Normalized Data':\n",
      "  C: [0.1, 1, 10, 100]\n",
      "  gamma: ['scale', 0.01, 0.1]\n",
      "  kernel: ['poly', 'rbf']\n",
      "  degree: [2, 3, 4]\n",
      "  coef0: [0.0, 0.5, 1.0]\n",
      "Total combinations: 216\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.983321\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.981622\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0078\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  C: 1\n",
      "  coef0: 0.0\n",
      "  degree: 3\n",
      "  gamma: scale\n",
      "  kernel: poly\n",
      "\n",
      "Best CV score: 0.960400\n",
      "\n",
      "================================================================================\n",
      "Configuration: SelectKBest\n",
      "================================================================================\n",
      "Hyperparameter grid for 'SelectKBest':\n",
      "  C: [0.1, 1, 10]\n",
      "  gamma: ['scale', 'auto', 0.01]\n",
      "  kernel: ['rbf', 'poly', 'linear']\n",
      "  degree: [2, 3]\n",
      "  coef0: [0.0, 0.1]\n",
      "Total combinations: 108\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.989364\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.987027\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0078\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  C: 10\n",
      "  coef0: 0.0\n",
      "  degree: 2\n",
      "  gamma: scale\n",
      "  kernel: rbf\n",
      "\n",
      "Best CV score: 0.958034\n",
      "\n",
      "================================================================================\n",
      "Configuration: RFECV\n",
      "================================================================================\n",
      "Hyperparameter grid for 'RFECV':\n",
      "  C: [0.5, 1, 5, 10]\n",
      "  gamma: ['scale', 0.001, 0.01]\n",
      "  kernel: ['rbf', 'sigmoid']\n",
      "  degree: [2, 3]\n",
      "  coef0: [0.0, 0.5]\n",
      "Total combinations: 96\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.968747\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.988973\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0078\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  C: 1\n",
      "  coef0: 0.0\n",
      "  degree: 2\n",
      "  gamma: scale\n",
      "  kernel: rbf\n",
      "\n",
      "Best CV score: 0.957822\n",
      "\n",
      "================================================================================\n",
      "Configuration: PCA\n",
      "================================================================================\n",
      "Hyperparameter grid for 'PCA':\n",
      "  C: [0.1, 1, 10, 50]\n",
      "  gamma: ['scale', 'auto', 0.01]\n",
      "  kernel: ['linear', 'sigmoid', 'rbf']\n",
      "  degree: [2]\n",
      "  coef0: [0.0, 0.5, 1.0]\n",
      "Total combinations: 108\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.978454\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.988757\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0078\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  C: 50\n",
      "  coef0: 0.0\n",
      "  degree: 2\n",
      "  gamma: auto\n",
      "  kernel: rbf\n",
      "\n",
      "Best CV score: 0.960400\n",
      "\n",
      "================================================================================\n",
      "Configuration: SMOTE + StandardScaler\n",
      "================================================================================\n",
      "Hyperparameter grid for 'SMOTE + StandardScaler':\n",
      "  model__C: [0.1, 1, 10, 100]\n",
      "  model__gamma: ['scale', 0.001, 0.01, 0.1]\n",
      "  model__kernel: ['rbf', 'poly', 'linear']\n",
      "  model__degree: [2, 3]\n",
      "  model__coef0: [0.0, 0.5]\n",
      "Total combinations: 192\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.965997  0.950871 0.946497   0.955439 0.993711\n",
      "    Test  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0217\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  model__C: 0.1\n",
      "  model__coef0: 0.5\n",
      "  model__degree: 3\n",
      "  model__gamma: 0.1\n",
      "  model__kernel: poly\n",
      "\n",
      "Best CV score: 0.956065\n",
      "\n",
      "================================================================================\n",
      "Configuration: SMOTE + GridSearchCV\n",
      "================================================================================\n",
      "Hyperparameter grid for 'SMOTE + GridSearchCV':\n",
      "  model__C: [0.1, 1, 10, 100]\n",
      "  model__gamma: ['scale', 0.001, 0.01, 0.1]\n",
      "  model__kernel: ['rbf', 'poly', 'linear']\n",
      "  model__degree: [2, 3]\n",
      "  model__coef0: [0.0, 0.5]\n",
      "Total combinations: 192\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "\n",
      "üìä Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.965997  0.950871 0.946497   0.955439 0.993711\n",
      "    Test  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "\n",
      "‚úì Good generalization. Train-Test gap: -0.0217\n",
      "\n",
      "üéØ Best hyperparameters found:\n",
      "  model__C: 0.1\n",
      "  model__coef0: 0.5\n",
      "  model__degree: 3\n",
      "  model__gamma: 0.1\n",
      "  model__kernel: poly\n",
      "\n",
      "Best CV score: 0.956065\n",
      "\n",
      "================================================================================\n",
      "‚úÖ SVM evaluation complete for all configurations.\n",
      "================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "MODEL PERFORMANCE RESULTS\n",
      "====================================================================================================\n",
      "ML Model          Configuration  Accuracy  F1 Score   Recall  Precision  ROC_AUC\n",
      "     SVM      Preprocessed Data  0.981481  0.973976 0.978486   0.969652 0.995676\n",
      "     SVM        Normalized Data  0.981481  0.973976 0.978486   0.969652 0.981622\n",
      "     SVM            SelectKBest  0.981481  0.973976 0.978486   0.969652 0.987027\n",
      "     SVM                  RFECV  0.981481  0.973976 0.978486   0.969652 0.988973\n",
      "     SVM                    PCA  0.981481  0.973976 0.978486   0.969652 0.988757\n",
      "     SVM SMOTE + StandardScaler  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "     SVM   SMOTE + GridSearchCV  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "\n",
      "üìà Final Results:\n",
      "ML Model          Configuration  Accuracy  F1 Score   Recall  Precision  ROC_AUC\n",
      "     SVM      Preprocessed Data  0.981481  0.973976 0.978486   0.969652 0.995676\n",
      "     SVM        Normalized Data  0.981481  0.973976 0.978486   0.969652 0.981622\n",
      "     SVM            SelectKBest  0.981481  0.973976 0.978486   0.969652 0.987027\n",
      "     SVM                  RFECV  0.981481  0.973976 0.978486   0.969652 0.988973\n",
      "     SVM                    PCA  0.981481  0.973976 0.978486   0.969652 0.988757\n",
      "     SVM SMOTE + StandardScaler  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "     SVM   SMOTE + GridSearchCV  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "\n",
      "üèÜ Sorted Results (by F1 Score):\n",
      "ML Model          Configuration  Accuracy  F1 Score   Recall  Precision  ROC_AUC\n",
      "     SVM SMOTE + StandardScaler  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "     SVM   SMOTE + GridSearchCV  0.987654  0.982810 0.992000   0.974359 0.996973\n",
      "     SVM      Preprocessed Data  0.981481  0.973976 0.978486   0.969652 0.995676\n",
      "     SVM        Normalized Data  0.981481  0.973976 0.978486   0.969652 0.981622\n",
      "     SVM            SelectKBest  0.981481  0.973976 0.978486   0.969652 0.987027\n",
      "     SVM                  RFECV  0.981481  0.973976 0.978486   0.969652 0.988973\n",
      "     SVM                    PCA  0.981481  0.973976 0.978486   0.969652 0.988757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SVM with Configuration-Specific Hyperparameter Grids\n",
    "# =============================================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Define preprocessor for categorical and numeric features\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "# Create preprocessing transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to get fully numeric data first\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "try:\n",
    "    feature_names = (numeric_features + \n",
    "                    list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))\n",
    "except:\n",
    "    feature_names = [f'feature_{i}' for i in range(X_train_preprocessed.shape[1])]\n",
    "\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=feature_names, index=X_train.index)\n",
    "X_val_preprocessed = pd.DataFrame(X_val_preprocessed, columns=feature_names, index=X_val.index)\n",
    "\n",
    "print(f\"\\nPreprocessed data shape: {X_train_preprocessed.shape}\")\n",
    "print(f\"All features are now numeric: {X_train_preprocessed.select_dtypes(include=np.number).shape[1] == X_train_preprocessed.shape[1]}\")\n",
    "\n",
    "# Clear previous results\n",
    "try:\n",
    "    clear_results()\n",
    "except:\n",
    "    ML_Model = []\n",
    "    ML_Config = []\n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    roc_auc = []\n",
    "    print(\"Initialized result storage lists.\")\n",
    "\n",
    "print(\"\\n=== START: SVM Configuration Sweep with Custom Hyperparameters ===\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration-Specific Hyperparameter Grids\n",
    "# =============================================================================\n",
    "\n",
    "# Grid 1: Preprocessed Data - Focus on RBF and linear kernels\n",
    "param_grid_1 = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'degree': [2],  # Not used for rbf/linear but required\n",
    "    'coef0': [0.0]\n",
    "}\n",
    "\n",
    "# Grid 2: Normalized Data - Explore polynomial kernels\n",
    "param_grid_2 = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.01, 0.1],\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'coef0': [0.0, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Grid 3: SelectKBest - Focus on simpler models\n",
    "param_grid_3 = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'linear'],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0.0, 0.1]\n",
    "}\n",
    "\n",
    "# Grid 4: RFECV - Similar to SelectKBest but different ranges\n",
    "param_grid_4 = {\n",
    "    'C': [0.5, 1, 5, 10],\n",
    "    'gamma': ['scale', 0.001, 0.01],\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'degree': [2, 3],\n",
    "    'coef0': [0.0, 0.5]\n",
    "}\n",
    "\n",
    "# Grid 5: PCA - Focus on linear and sigmoid\n",
    "param_grid_5 = {\n",
    "    'C': [0.1, 1, 10, 50],\n",
    "    'gamma': ['scale', 'auto', 0.01],\n",
    "    'kernel': ['linear', 'sigmoid', 'rbf'],\n",
    "    'degree': [2],\n",
    "    'coef0': [0.0, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Grid 6 & 7: SMOTE pipelines - Balanced approach\n",
    "param_grid_smote = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'model__kernel': ['rbf', 'poly', 'linear'],\n",
    "    'model__degree': [2, 3],\n",
    "    'model__coef0': [0.0, 0.5]\n",
    "}\n",
    "\n",
    "# Map grids to configurations\n",
    "hyperparameter_grids = {\n",
    "    'Preprocessed Data': param_grid_1,\n",
    "    'Normalized Data': param_grid_2,\n",
    "    'SelectKBest': param_grid_3,\n",
    "    'RFECV': param_grid_4,\n",
    "    'PCA': param_grid_5,\n",
    "    'SMOTE + StandardScaler': param_grid_smote,\n",
    "    'SMOTE + GridSearchCV': param_grid_smote\n",
    "}\n",
    "\n",
    "# Initialize configurations list\n",
    "configurations = []\n",
    "\n",
    "# --- Configuration 1: Preprocessed Data ---\n",
    "configurations.append(('Preprocessed Data', 'array', X_train_preprocessed, X_val_preprocessed))\n",
    "print(\"‚úì Configuration 1: Preprocessed Data\")\n",
    "\n",
    "# --- Configuration 2: Normalized Data (MinMax on preprocessed) ---\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_normalized = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(X_train_preprocessed), \n",
    "    columns=X_train_preprocessed.columns, \n",
    "    index=X_train_preprocessed.index\n",
    ")\n",
    "X_val_normalized = pd.DataFrame(\n",
    "    scaler_minmax.transform(X_val_preprocessed), \n",
    "    columns=X_val_preprocessed.columns, \n",
    "    index=X_val_preprocessed.index\n",
    ")\n",
    "configurations.append(('Normalized Data', 'array', X_train_normalized, X_val_normalized))\n",
    "print(\"‚úì Configuration 2: Normalized Data (MinMax)\")\n",
    "\n",
    "# --- Configuration 3: SelectKBest ---\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "max_features = min(X_train_normalized.shape[1], 20)\n",
    "\n",
    "for k in range(1, max_features + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_tr_k = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(\n",
    "        SVC(kernel='linear', random_state=RANDOM_STATE), \n",
    "        X_tr_k, y_train, cv=5, scoring='accuracy', n_jobs=-1\n",
    "    ).mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = int(np.argmax(scores) + 1)\n",
    "print(f\"Optimal number of features: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = pd.DataFrame(\n",
    "    kbest.fit_transform(X_train_normalized, y_train), \n",
    "    columns=X_train_normalized.columns[kbest.get_support()]\n",
    ")\n",
    "X_val_kbest = pd.DataFrame(\n",
    "    kbest.transform(X_val_normalized), \n",
    "    columns=X_train_kbest.columns\n",
    ")\n",
    "configurations.append(('SelectKBest', 'array', X_train_kbest, X_val_kbest))\n",
    "print(\"‚úì Configuration 3: SelectKBest\")\n",
    "\n",
    "# --- Configuration 4: RFECV ---\n",
    "print(\"\\n=== RFECV Feature Selection ===\")\n",
    "svm_estimator = SVC(kernel='linear', random_state=RANDOM_STATE)\n",
    "rfecv = RFECV(\n",
    "    estimator=svm_estimator, \n",
    "    step=1, \n",
    "    cv=StratifiedKFold(5), \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = pd.DataFrame(\n",
    "    rfe.fit_transform(X_train_kbest, y_train), \n",
    "    columns=X_train_kbest.columns[rfe.get_support()]\n",
    ")\n",
    "X_val_rfe = pd.DataFrame(\n",
    "    rfe.transform(X_val_kbest), \n",
    "    columns=X_train_rfe.columns\n",
    ")\n",
    "configurations.append(('RFECV', 'array', X_train_rfe, X_val_rfe))\n",
    "print(\"‚úì Configuration 4: RFECV\")\n",
    "\n",
    "# --- Configuration 5: PCA ---\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca_full = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = int(np.argmax(cumulative_variance >= desired_variance) + 1)\n",
    "n_components = max(2, n_components)\n",
    "print(f'Number of components for {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=RANDOM_STATE)\n",
    "X_train_pca = pd.DataFrame(pca.fit_transform(X_train_rfe), index=X_train_rfe.index)\n",
    "X_val_pca = pd.DataFrame(pca.transform(X_val_rfe), index=X_val_rfe.index)\n",
    "configurations.append(('PCA', 'array', X_train_pca, X_val_pca))\n",
    "print(\"‚úì Configuration 5: PCA\")\n",
    "\n",
    "# --- Configuration 6: SMOTE + StandardScaler (Pipeline) ---\n",
    "pipeline_smote_scaler = ImbPipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('model', SVC(probability=True, random_state=RANDOM_STATE))\n",
    "])\n",
    "configurations.append(('SMOTE + StandardScaler', 'pipeline', pipeline_smote_scaler, None))\n",
    "print(\"‚úì Configuration 6: SMOTE + StandardScaler (Pipeline)\")\n",
    "\n",
    "# --- Configuration 7: SMOTE + GridSearchCV (Pipeline) ---\n",
    "pipeline_smote_grid = ImbPipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('model', SVC(probability=True, random_state=RANDOM_STATE))\n",
    "])\n",
    "configurations.append(('SMOTE + GridSearchCV', 'pipeline', pipeline_smote_grid, None))\n",
    "print(\"‚úì Configuration 7: SMOTE + GridSearchCV (Pipeline)\")\n",
    "\n",
    "# Safe ROC AUC helper\n",
    "def safe_roc_auc(y_true, y_proba):\n",
    "    try:\n",
    "        if isinstance(y_proba, np.ndarray) and y_proba.shape[1] == 2:\n",
    "            return metrics.roc_auc_score(y_true, y_proba[:, 1])\n",
    "        else:\n",
    "            return metrics.roc_auc_score(\n",
    "                pd.get_dummies(y_true), y_proba, \n",
    "                multi_class='ovr', average='macro'\n",
    "            )\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# =============================================================================\n",
    "# Run SVM with Configuration-Specific GridSearchCV\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING SVM WITH CONFIGURATION-SPECIFIC HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, kind, X_tr_cfg, X_val_cfg in configurations:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Configuration: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get the specific parameter grid for this configuration\n",
    "    param_grid = hyperparameter_grids[name]\n",
    "    \n",
    "    print(f\"Hyperparameter grid for '{name}':\")\n",
    "    for key, values in param_grid.items():\n",
    "        print(f\"  {key}: {values}\")\n",
    "    print(f\"Total combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "    \n",
    "    try:\n",
    "        if kind == 'pipeline':\n",
    "            pipeline = X_tr_cfg\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline, param_grid, \n",
    "                cv=5, n_jobs=-1, verbose=1, scoring='f1_macro'\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_train_pred = best_model.predict(X_train)\n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "            y_train_proba = best_model.predict_proba(X_train)\n",
    "            y_val_proba = best_model.predict_proba(X_val)\n",
    "        else:\n",
    "            grid_search = GridSearchCV(\n",
    "                SVC(probability=True, random_state=RANDOM_STATE), \n",
    "                param_grid, cv=5, n_jobs=-1, verbose=1, scoring='f1_macro'\n",
    "            )\n",
    "            grid_search.fit(X_tr_cfg, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_train_pred = best_model.predict(X_tr_cfg)\n",
    "            y_val_pred = best_model.predict(X_val_cfg)\n",
    "            y_train_proba = best_model.predict_proba(X_tr_cfg)\n",
    "            y_val_proba = best_model.predict_proba(X_val_cfg)\n",
    "\n",
    "        # Calculate train-test gap for overfitting detection\n",
    "        train_acc = metrics.accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = metrics.accuracy_score(y_val, y_val_pred)\n",
    "        train_test_gap = train_acc - test_acc\n",
    "\n",
    "        # Build metrics dictionary\n",
    "        metrics_dict = {\n",
    "            \"Dataset\": [\"Training\", \"Test\"],\n",
    "            \"Accuracy\": [train_acc, test_acc],\n",
    "            \"F1 Score\": [\n",
    "                metrics.f1_score(y_train, y_train_pred, average='macro'),\n",
    "                metrics.f1_score(y_val, y_val_pred, average='macro'),\n",
    "            ],\n",
    "            \"Recall\": [\n",
    "                metrics.recall_score(y_train, y_train_pred, average='macro'),\n",
    "                metrics.recall_score(y_val, y_val_pred, average='macro'),\n",
    "            ],\n",
    "            \"Precision\": [\n",
    "                metrics.precision_score(y_train, y_train_pred, average='macro', zero_division=0),\n",
    "                metrics.precision_score(y_val, y_val_pred, average='macro', zero_division=0),\n",
    "            ],\n",
    "            \"AUC-ROC\": [\n",
    "                safe_roc_auc(y_train, y_train_proba),\n",
    "                safe_roc_auc(y_val, y_val_proba),\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        df_metrics = pd.DataFrame(metrics_dict)\n",
    "        pd.options.display.float_format = '{:.6f}'.format\n",
    "        print(\"\\nüìä Support Vector Machine Model Performance Metrics\")\n",
    "        print(df_metrics.to_string(index=False))\n",
    "\n",
    "        # Overfitting warning\n",
    "        if train_test_gap > 0.10:\n",
    "            print(f\"\\n‚ö†Ô∏è  WARNING: Overfitting detected! Train-Test gap: {train_test_gap:.4f}\")\n",
    "        elif train_test_gap < 0.05:\n",
    "            print(f\"\\n‚úì Good generalization. Train-Test gap: {train_test_gap:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\n‚Üí Acceptable gap: {train_test_gap:.4f}\")\n",
    "\n",
    "        # Store test metrics\n",
    "        test_metrics = df_metrics[df_metrics['Dataset'] == 'Test'].iloc[0]\n",
    "        try:\n",
    "            store_results(\n",
    "                'SVM',\n",
    "                name,\n",
    "                float(test_metrics['Accuracy']),\n",
    "                float(test_metrics['F1 Score']),\n",
    "                float(test_metrics['Recall']),\n",
    "                float(test_metrics['Precision']),\n",
    "                float(test_metrics['AUC-ROC'])\n",
    "            )\n",
    "        except:\n",
    "            ML_Model.append('SVM')\n",
    "            ML_Config.append(name)\n",
    "            accuracy.append(round(float(test_metrics['Accuracy']), 6))\n",
    "            f1.append(round(float(test_metrics['F1 Score']), 6))\n",
    "            recall.append(round(float(test_metrics['Recall']), 6))\n",
    "            precision.append(round(float(test_metrics['Precision']), 6))\n",
    "            roc_auc.append(round(float(test_metrics['AUC-ROC']), 6))\n",
    "\n",
    "        print(\"\\nüéØ Best hyperparameters found:\")\n",
    "        best_params = grid_search.best_params_\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"  {param}: {value}\")\n",
    "        print(f\"\\nBest CV score: {grid_search.best_score_:.6f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in configuration '{name}': {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SVM evaluation complete for all configurations.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display final results\n",
    "try:\n",
    "    display_and_save_results('svm_all_configs')\n",
    "except:\n",
    "    result = pd.DataFrame({\n",
    "        'ML Model': ML_Model,\n",
    "        'Configuration': ML_Config,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'ROC_AUC': roc_auc,\n",
    "    })\n",
    "    print(\"\\nüìà Final Results:\")\n",
    "    print(result.to_string(index=False))\n",
    "    \n",
    "    # Sort by F1 Score\n",
    "    sorted_result = result.sort_values(by=['F1 Score', 'Accuracy'], ascending=False).reset_index(drop=True)\n",
    "    print(\"\\nüèÜ Sorted Results (by F1 Score):\")\n",
    "    print(sorted_result.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50abe0",
   "metadata": {},
   "source": [
    "### SVM with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61756ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration 1: 'SMOTE + StandardScaler' pipeline defined.\n",
      "Configuration 2: 'StandardScaler Only' data prepared.\n",
      "\n",
      "Finding optimal components for PCA (95% variance)...\n",
      "Number of components for 95% variance: 8\n",
      "Configuration 3: 'PCA (95% Var)' data prepared.\n",
      "\n",
      "================================================================================\n",
      "RUNNING SVM WITH HYPERPARAMETER TUNING ON ALL CONFIGURATIONS\n",
      "================================================================================\n",
      "Results cleared!\n",
      "\n",
      "--- Running SVM with 'SMOTE + StandardScaler' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best cross-validation F1-Score for 'SMOTE + StandardScaler': 0.9623\n",
      "Validation F1-Score: 0.9816\n",
      "Best params: {'model__C': 1, 'model__gamma': 'auto', 'model__kernel': 'rbf'}\n",
      "\n",
      "--- Running SVM with 'StandardScaler Only' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best cross-validation F1-Score for 'StandardScaler Only': 0.9714\n",
      "Validation F1-Score: 0.9753\n",
      "Best params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "--- Running SVM with 'PCA (95% Var)' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best cross-validation F1-Score for 'PCA (95% Var)': 0.9667\n",
      "Validation F1-Score: 0.9816\n",
      "Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "--- SVM evaluation complete for all configurations. ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# This list will hold different versions of our data for testing\n",
    "configurations = []\n",
    "\n",
    "# Define numeric and categorical features from our loaded X_train\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Create a standard preprocessor for scaling and encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# --- Configuration 1: The approach from main.ipynb (SMOTE + StandardScaler) ---\n",
    "# This is a pipeline, not a pre-transformed dataset. We will handle it specially in the loop.\n",
    "configurations.append(('SMOTE + StandardScaler', None, None))\n",
    "print(\"Configuration 1: 'SMOTE + StandardScaler' pipeline defined.\")\n",
    "\n",
    "# --- Configuration 2: Scaled Data (No SMOTE) ---\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_val_scaled = preprocessor.transform(X_val)\n",
    "configurations.append(('StandardScaler Only', X_train_scaled, X_val_scaled))\n",
    "print(\"Configuration 2: 'StandardScaler Only' data prepared.\")\n",
    "\n",
    "# --- Configuration 3: PCA with 95% Variance (on Scaled Data) ---\n",
    "print(\"\\nFinding optimal components for PCA (95% variance)...\")\n",
    "pca_explorer = PCA().fit(X_train_scaled)\n",
    "cumulative_variance = np.cumsum(pca_explorer.explained_variance_ratio_)\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of components for 95% variance: {n_components_95}\")\n",
    "\n",
    "pca = PCA(n_components=n_components_95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "configurations.append(('PCA (95% Var)', X_train_pca, X_val_pca))\n",
    "print(\"Configuration 3: 'PCA (95% Var)' data prepared.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. RUN SVM WITH GRIDSEARCHCV ON ALL CONFIGURATIONS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING SVM WITH HYPERPARAMETER TUNING ON ALL CONFIGURATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define the hyperparameter grid for SVM\n",
    "# Note: 'model__' prefix is used for the SMOTE pipeline configuration\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "param_grid_svm_pipeline = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__gamma': ['scale', 'auto'],\n",
    "    'model__kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Clear previous results\n",
    "clear_results()\n",
    "\n",
    "# Loop through each data configuration\n",
    "for name, X_train_cfg, X_val_cfg in configurations:\n",
    "    print(f\"\\n--- Running SVM with '{name}' configuration ---\")\n",
    "    \n",
    "    # Special handling for the SMOTE pipeline configuration\n",
    "    if name == 'SMOTE + StandardScaler':\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('model', SVC(probability=True, random_state=42))\n",
    "        ])\n",
    "        grid_search = GridSearchCV(pipeline, param_grid_svm_pipeline, cv=5, n_jobs=-1, verbose=1, scoring='f1_weighted')\n",
    "        # Fit on the original X_train, y_train\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        # Make predictions on the original X_val\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "    else: # For all other configurations where data is already transformed\n",
    "        grid_search = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=5, n_jobs=-1, verbose=1, scoring='f1_weighted')\n",
    "        # Fit on the pre-processed configuration data\n",
    "        grid_search.fit(X_train_cfg, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        # Make predictions on the pre-processed validation data\n",
    "        y_pred = best_model.predict(X_val_cfg)\n",
    "        y_proba = best_model.predict_proba(X_val_cfg)[:, 1]\n",
    "\n",
    "    # --- Metrics Calculation (consistent for all loops) ---\n",
    "    le = LabelEncoder()\n",
    "    y_val_encoded = le.fit_transform(y_val)\n",
    "    y_pred_encoded = le.transform(y_pred)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_val_encoded, y_pred_encoded)\n",
    "    f1_val = metrics.f1_score(y_val_encoded, y_pred_encoded, average='weighted')\n",
    "    rec = metrics.recall_score(y_val_encoded, y_pred_encoded, average='weighted')\n",
    "    prec = metrics.precision_score(y_val_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
    "    roc = metrics.roc_auc_score(y_val_encoded, y_proba)\n",
    "    \n",
    "    store_results('SVM', name, acc, f1_val, rec, prec, roc)\n",
    "    \n",
    "    print(f\"Best cross-validation F1-Score for '{name}': {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Validation F1-Score: {f1_val:.4f}\")\n",
    "    print(f\"Best params: {grid_search.best_params_}\")\n",
    "\n",
    "print(\"\\n--- SVM evaluation complete for all configurations. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822a9fe",
   "metadata": {},
   "source": [
    "### SVM with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea0372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration 1: 'SMOTE + StandardScaler' pipeline defined.\n",
      "Configuration 2: 'StandardScaler Only' data prepared.\n",
      "\n",
      "Applying PCA to retain 99% of variance...\n",
      "PCA (99%) applied. Number of components selected: 10\n",
      "\n",
      "================================================================================\n",
      "RUNNING SVM WITH HYPERPARAMETER TUNING ON ALL CONFIGURATIONS\n",
      "================================================================================\n",
      "Results cleared!\n",
      "\n",
      "--- Running SVM with 'SMOTE + StandardScaler' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.967543  0.953674 0.954775   0.952585 0.993192\n",
      "    Test  0.981481  0.973976 0.978486   0.969652 0.997622\n",
      "\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'model__C': 1, 'model__gamma': 'auto', 'model__kernel': 'rbf'}\n",
      "\n",
      "--- Running SVM with 'StandardScaler Only' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.981052\n",
      "    Test  0.975309  0.964973 0.964973   0.964973 0.993946\n",
      "\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "--- Running SVM with 'PCA (99% Var)' configuration ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Support Vector Machine Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973725  0.960749 0.941781   0.983591 0.981229\n",
      "    Test  0.975309  0.964973 0.964973   0.964973 0.993514\n",
      "\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "--- SVM evaluation complete for all configurations. ---\n"
     ]
    }
   ],
   "source": [
    "# # Store different configurations\n",
    "# configurations = []\n",
    "# configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# # Step 2: Normalize the data\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_normalized = scaler.fit_transform(X_train)\n",
    "# X_test_normalized = scaler.transform(X_test)\n",
    "# configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# # Step 3.1: SelectKBest\n",
    "# print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "# scores = []\n",
    "# for k in range(1, X_train.shape[1] + 1):\n",
    "#     kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "#     X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "#     score = cross_val_score(SVC(kernel='linear'), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "#     scores.append(score)\n",
    "\n",
    "# optimal_k = scores.index(max(scores)) + 1\n",
    "# print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "# kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "# X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "# X_test_kbest = kbest.transform(X_test_normalized)\n",
    "# selected_features_kbest = X.columns[kbest.get_support()]\n",
    "# configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# # Step 3.2: RFECV\n",
    "# print(\"\\n=== RFECV Feature Selection with SVM ===\")\n",
    "# svm_estimator = SVC(kernel='linear')\n",
    "\n",
    "# rfecv = RFECV(estimator=svm_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "# rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "# print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "# rfe = RFE(estimator=svm_estimator, n_features_to_select=rfecv.n_features_)\n",
    "# X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "# X_test_rfe = rfe.transform(X_test_kbest)\n",
    "# selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "# configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# # Step 3.3: PCA\n",
    "# print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "# pca = PCA().fit(X_train_rfe)\n",
    "# cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "# desired_variance = 0.99\n",
    "# n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "# print(f'Number of components that explain {desired_variance*100}% variance: {n_components}')\n",
    "\n",
    "# pca = PCA(n_components=n_components)\n",
    "# X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "# X_test_pca = pca.transform(X_test_rfe)\n",
    "# configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# # Step 4: SVM + GridSearchCV\n",
    "# print(\"\\n=== SVM Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "#     'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "#     'degree': [2, 3, 4],\n",
    "#     'coef0': [0.0, 0.1, 0.5, 1.0]\n",
    "# }\n",
    "\n",
    "# for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "#     print(f\"\\nRunning SVM with {name} configuration...\")\n",
    "#     svc = GridSearchCV(SVC(probability=True), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "#     svc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "#     y_train_svc = svc.predict(X_train_cfg)\n",
    "#     y_test_svc = svc.predict(X_test_cfg)\n",
    "#     y_train_svc_proba = svc.predict_proba(X_train_cfg)\n",
    "#     y_test_svc_proba = svc.predict_proba(X_test_cfg)\n",
    "\n",
    "#     metrics_dict = {\n",
    "#         \"Dataset\": [\"Training\", \"Test\"],\n",
    "#         \"Accuracy\": [\n",
    "#             metrics.accuracy_score(y_train_cfg, y_train_svc),\n",
    "#             metrics.accuracy_score(y_test, y_test_svc),\n",
    "#         ],\n",
    "#         \"F1 Score\": [\n",
    "#             metrics.f1_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "#             metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "#         ],\n",
    "#         \"Recall\": [\n",
    "#             metrics.recall_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "#             metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "#         ],\n",
    "#         \"Precision\": [\n",
    "#             metrics.precision_score(y_train_cfg, y_train_svc, average='macro'),\n",
    "#             metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "#         ],\n",
    "#         \"AUC-ROC\": [\n",
    "#             metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_svc_proba, multi_class='ovr', average='macro'),\n",
    "#             metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro'),\n",
    "#         ]\n",
    "#     }\n",
    "\n",
    "#     df_metrics = pd.DataFrame(metrics_dict)\n",
    "#     print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "#     print(df_metrics.to_string(index=False))\n",
    "\n",
    "#     auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_svc_proba, multi_class='ovr', average='macro')\n",
    "#     storeResults(\n",
    "#         'Support Vector Machine 99',\n",
    "#         name,\n",
    "#         metrics.accuracy_score(y_test, y_test_svc),\n",
    "#         metrics.f1_score(y_test, y_test_svc, average='macro'),\n",
    "#         metrics.recall_score(y_test, y_test_svc, average='macro'),\n",
    "#         metrics.precision_score(y_test, y_test_svc, average='macro'),\n",
    "#         auc_score\n",
    "#     )\n",
    "\n",
    "#     print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "#     print(svc.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SVM Model with Multiple Preprocessing Configurations (including PCA 99%)\n",
    "# =============================================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# This list will hold different versions of our data for testing\n",
    "configurations = []\n",
    "\n",
    "# Define a standard preprocessor for reuse\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# --- Configuration 1: The approach from main.ipynb (SMOTE + StandardScaler) ---\n",
    "# This is a pipeline, not a pre-transformed dataset. We will handle it specially in the loop.\n",
    "configurations.append(('SMOTE + StandardScaler', None, None))\n",
    "print(\"Configuration 1: 'SMOTE + StandardScaler' pipeline defined.\")\n",
    "\n",
    "# --- Configuration 2: Scaled Data (No SMOTE) ---\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_val_scaled = preprocessor.transform(X_val)\n",
    "configurations.append(('StandardScaler Only', X_train_scaled, X_val_scaled))\n",
    "print(\"Configuration 2: 'StandardScaler Only' data prepared.\")\n",
    "\n",
    "# --- Configuration 3: PCA with 99% Variance (on Scaled Data) ---\n",
    "print(\"\\nApplying PCA to retain 99% of variance...\")\n",
    "pca_99 = PCA(n_components=0.99)\n",
    "X_train_pca_99 = pca_99.fit_transform(X_train_scaled)\n",
    "X_val_pca_99 = pca_99.transform(X_val_scaled)\n",
    "configurations.append(('PCA (99% Var)', X_train_pca_99, X_val_pca_99))\n",
    "print(f\"PCA (99%) applied. Number of components selected: {pca_99.n_components_}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. RUN SVM WITH GRIDSEARCHCV ON ALL CONFIGURATIONS\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING SVM WITH HYPERPARAMETER TUNING ON ALL CONFIGURATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define the hyperparameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'poly']\n",
    "}\n",
    "param_grid_svm_pipeline = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__gamma': ['scale', 'auto'],\n",
    "    'model__kernel': ['rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Clear previous results before this run\n",
    "clear_results()\n",
    "\n",
    "# Loop through each data configuration\n",
    "for name, X_train_cfg, X_val_cfg in configurations:\n",
    "    print(f\"\\n--- Running SVM with '{name}' configuration ---\")\n",
    "    \n",
    "    # Special handling for the SMOTE pipeline configuration\n",
    "    if name == 'SMOTE + StandardScaler':\n",
    "        pipeline = ImbPipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('model', SVC(probability=True, random_state=42))\n",
    "        ])\n",
    "        grid_search = GridSearchCV(pipeline, param_grid_svm_pipeline, cv=5, n_jobs=-1, verbose=1, scoring='f1_weighted')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        y_train_proba = best_model.predict_proba(X_train)\n",
    "        y_val_proba = best_model.predict_proba(X_val)\n",
    "        \n",
    "    else: # For all other configurations where data is already transformed\n",
    "        grid_search = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm, cv=5, n_jobs=-1, verbose=1, scoring='f1_weighted')\n",
    "        grid_search.fit(X_train_cfg, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_train_pred = best_model.predict(X_train_cfg)\n",
    "        y_val_pred = best_model.predict(X_val_cfg)\n",
    "        y_train_proba = best_model.predict_proba(X_train_cfg)\n",
    "        y_val_proba = best_model.predict_proba(X_val_cfg)\n",
    "\n",
    "    # --- Create the metrics_dict with Training and Test results ---\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train, y_train_pred),\n",
    "            metrics.accuracy_score(y_val, y_val_pred),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.f1_score(y_val, y_val_pred, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.recall_score(y_val, y_val_pred, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train, y_train_pred, average='macro', zero_division=0),\n",
    "            metrics.precision_score(y_val, y_val_pred, average='macro', zero_division=0),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train), y_train_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_val), y_val_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Display Results and Store Test Metrics\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nSupport Vector Machine Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "    \n",
    "    test_metrics = df_metrics[df_metrics['Dataset'] == 'Test']\n",
    "    store_results(\n",
    "        'SVM',\n",
    "        name,\n",
    "        test_metrics['Accuracy'].iloc[0],\n",
    "        test_metrics['F1 Score'].iloc[0],\n",
    "        test_metrics['Recall'].iloc[0],\n",
    "        test_metrics['Precision'].iloc[0],\n",
    "        test_metrics['AUC-ROC'].iloc[0]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBest hyperparameters found by GridSearchCV:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n--- SVM evaluation complete for all configurations. ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce270e1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107a01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results storage framework loaded successfully!\n",
      "Available functions (aliases included):\n",
      "- store_results(model, config, accuracy, f1, recall, precision, auc_roc)\n",
      "- storeResults(...)  # alias\n",
      "- display_and_save_results(filename_prefix='model_exploration') -> (display_df, sorted_df)\n",
      "- displayAndSaveResults(...)  # alias\n",
      "- clear_results() / clearResults()\n",
      "- plot_model_comparison(result_df=None, plot_filename=None) / plotModelComparison(...)\n"
     ]
    }
   ],
   "source": [
    "# ML Model Results Storage Framework ‚Äî improved & backwards-compatible\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "# --- Directories (matches your current code) ---\n",
    "results_dir = 'ModelExploration/results'\n",
    "plots_dir = 'ModelExploration/plots'\n",
    "models_dir = 'ModelExploration/models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# --- Internal storage (single source-of-truth) ---\n",
    "_RESULTS: List[Dict[str, object]] = []\n",
    "\n",
    "# Also expose old-style lists for maximum compatibility (if other cells read them)\n",
    "ML_Model: List[str] = []\n",
    "ML_Config: List[str] = []\n",
    "accuracy: List[float] = []\n",
    "f1: List[float] = []\n",
    "recall: List[float] = []\n",
    "precision: List[float] = []\n",
    "roc_auc: List[float] = []\n",
    "\n",
    "# --- Core store function (raw floats: 0..1) ---\n",
    "def store_results(model: str, config: str, acc: float, f1_score: float, rec: float, prec: float, roc: float) -> None:\n",
    "    \"\"\"\n",
    "    Store a single result entry (raw floats 0..1).\n",
    "    Appends to both _RESULTS and legacy lists ML_Model / ML_Config / accuracy / ...\n",
    "    \"\"\"\n",
    "    entry = {\n",
    "        \"ML Model\": str(model),\n",
    "        \"Configuration\": str(config),\n",
    "        \"Accuracy\": float(acc),\n",
    "        \"F1 Score\": float(f1_score),\n",
    "        \"Recall\": float(rec),\n",
    "        \"Precision\": float(prec),\n",
    "        \"ROC_AUC\": float(roc)\n",
    "    }\n",
    "    _RESULTS.append(entry)\n",
    "    # keep legacy lists in sync\n",
    "    ML_Model.append(entry[\"ML Model\"])\n",
    "    ML_Config.append(entry[\"Configuration\"])\n",
    "    accuracy.append(round(entry[\"Accuracy\"], 6))\n",
    "    f1.append(round(entry[\"F1 Score\"], 6))\n",
    "    recall.append(round(entry[\"Recall\"], 6))\n",
    "    precision.append(round(entry[\"Precision\"], 6))\n",
    "    roc_auc.append(round(entry[\"ROC_AUC\"], 6))\n",
    "\n",
    "# CamelCase alias used in your code\n",
    "def storeResults(model: str, config: str, acc: float, f1_score: float, rec: float, prec: float, roc: float) -> None:\n",
    "    store_results(model, config, acc, f1_score, rec, prec, roc)\n",
    "\n",
    "# --- Clear stored results ---\n",
    "def clear_results() -> None:\n",
    "    \"\"\"Clear internal and legacy storage.\"\"\"\n",
    "    global _RESULTS, ML_Model, ML_Config, accuracy, f1, recall, precision, roc_auc\n",
    "    _RESULTS = []\n",
    "    ML_Model = []\n",
    "    ML_Config = []\n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    roc_auc = []\n",
    "    print(\"Results cleared!\")\n",
    "\n",
    "def clearResults() -> None:\n",
    "    clear_results()\n",
    "\n",
    "# --- Helpers to produce DataFrames ---\n",
    "def _results_raw_df() -> pd.DataFrame:\n",
    "    \"\"\"Return raw numeric DataFrame (floats 0..1).\"\"\"\n",
    "    if not _RESULTS:\n",
    "        cols = [\"ML Model\", \"Configuration\", \"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    df = pd.DataFrame(_RESULTS)\n",
    "    # drop duplicates keeping last (so new runs overwrite older ones)\n",
    "    df = df.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], keep='last').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def _results_display_df() -> pd.DataFrame:\n",
    "    \"\"\"Return display DataFrame with numeric formatting (6 decimals) matching your examples.\"\"\"\n",
    "    df = _results_raw_df().copy()\n",
    "    # Format numeric columns as floats with 6 decimal places (not percent strings)\n",
    "    for col in [\"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(float).map(lambda x: float(f\"{x:.6f}\"))\n",
    "    return df\n",
    "\n",
    "# --- Display & Save (CSV) ---\n",
    "def display_and_save_results(filename_prefix: str = 'model_exploration') -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create display DataFrame and sorted DataFrame, print them, and save two CSVs:\n",
    "      - {results_dir}/{filename_prefix}_results.csv\n",
    "      - {results_dir}/sorted_{filename_prefix}_results.csv\n",
    "    Returns (display_df, sorted_display_df)\n",
    "    \"\"\"\n",
    "    df_display = _results_display_df()\n",
    "    if df_display.empty:\n",
    "        print(\"No results to display. Use store_results(...) to add entries first.\")\n",
    "        return df_display, df_display\n",
    "\n",
    "    # Save raw display CSV (numeric floats)\n",
    "    out_csv = os.path.join(results_dir, f'{filename_prefix}_results.csv')\n",
    "    df_display.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nSaved results to: {out_csv}\")\n",
    "\n",
    "    # Sorted by F1 Score then Accuracy (descending), like your example\n",
    "    df_raw_sorted = _results_raw_df().sort_values(by=[\"F1 Score\", \"Accuracy\"], ascending=False).reset_index(drop=True)\n",
    "    df_sorted_display = df_raw_sorted.copy()\n",
    "    for col in [\"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]:\n",
    "        if col in df_sorted_display.columns:\n",
    "            df_sorted_display[col] = df_sorted_display[col].astype(float).map(lambda x: float(f\"{x:.6f}\"))\n",
    "\n",
    "    sorted_csv = os.path.join(results_dir, f'sorted_{filename_prefix}_results.csv')\n",
    "    df_sorted_display.to_csv(sorted_csv, index=False)\n",
    "    print(f\"Saved sorted results to: {sorted_csv}\\n\")\n",
    "\n",
    "    # Print tables\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL PERFORMANCE RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(df_display.to_string(index=False))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SORTED MODEL PERFORMANCE RESULTS (by F1 Score and Accuracy)\")\n",
    "    print(\"=\"*100)\n",
    "    print(df_sorted_display.to_string(index=False))\n",
    "\n",
    "    return df_display, df_sorted_display\n",
    "\n",
    "# CamelCase alias\n",
    "def displayAndSaveResults(filename_prefix: str = 'model_exploration') -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    return display_and_save_results(filename_prefix)\n",
    "\n",
    "# --- Plotting function ---\n",
    "def plot_model_comparison(result_df: Optional[pd.DataFrame] = None, plot_filename: str = \"model_performance_comparison.png\") -> None:\n",
    "    \"\"\"\n",
    "    Plot average performance per model across stored configurations.\n",
    "    If result_df is None, uses the saved sorted CSV (if exists) or internal results.\n",
    "    The plot is saved to plots_dir.\n",
    "    \"\"\"\n",
    "    if result_df is None:\n",
    "        candidate = os.path.join(results_dir, 'sorted_model_exploration_results.csv')\n",
    "        if os.path.exists(candidate):\n",
    "            result_df = pd.read_csv(candidate)\n",
    "        else:\n",
    "            _, result_df = display_and_save_results()\n",
    "    if result_df.empty:\n",
    "        print(\"No results available to plot.\")\n",
    "        return\n",
    "\n",
    "    df_plot = result_df.copy()\n",
    "    # ensure numeric floats (0..1) -> convert to 0..100 for plotting percentage axis\n",
    "    for col in [\"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]:\n",
    "        if df_plot[col].dtype == object:\n",
    "            # convert strings to floats if necessary\n",
    "            df_plot[col] = df_plot[col].astype(float)\n",
    "    df_plot[[\"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]] = df_plot[[\"Accuracy\", \"F1 Score\", \"Recall\", \"Precision\", \"ROC_AUC\"]] * 100.0\n",
    "\n",
    "    metrics_cols = ['Accuracy', 'F1 Score', 'Recall', 'Precision', 'ROC_AUC']\n",
    "    grouped = df_plot.groupby('ML Model')[metrics_cols].mean().sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    n_metrics = len(metrics_cols)\n",
    "    fig, axes = plt.subplots(1, n_metrics, figsize=(5 * n_metrics, 6), sharey=True)\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, metric in enumerate(metrics_cols):\n",
    "        ax = axes[i]\n",
    "        vals = grouped[metric]\n",
    "        sns.barplot(x=vals.index, y=vals.values, ax=ax, palette='Blues_r')\n",
    "        ax.set_title(metric)\n",
    "        ax.set_ylabel(metric + \" (%)\")\n",
    "        ax.set_xlabel('')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        # annotate\n",
    "        for p in ax.patches:\n",
    "            h = p.get_height()\n",
    "            ax.text(p.get_x() + p.get_width() / 2., h, f'{h:.2f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(plots_dir, plot_filename)\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved model comparison plot to: {out_path}\")\n",
    "\n",
    "# CamelCase alias\n",
    "def plotModelComparison(result_df: Optional[pd.DataFrame] = None, plot_filename: str = \"model_performance_comparison.png\") -> None:\n",
    "    plot_model_comparison(result_df=result_df, plot_filename=plot_filename)\n",
    "\n",
    "# --- End framework ---\n",
    "print(\"Model results storage framework loaded successfully!\")\n",
    "print(\"Available functions (aliases included):\")\n",
    "print(\"- store_results(model, config, accuracy, f1, recall, precision, auc_roc)\")\n",
    "print(\"- storeResults(...)  # alias\")\n",
    "print(\"- display_and_save_results(filename_prefix='model_exploration') -> (display_df, sorted_df)\")\n",
    "print(\"- displayAndSaveResults(...)  # alias\")\n",
    "print(\"- clear_results() / clearResults()\")\n",
    "print(\"- plot_model_comparison(result_df=None, plot_filename=None) / plotModelComparison(...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results cleared!\n",
      "\n",
      "=== START: RandomForest configuration sweep ===\n",
      "\n",
      "=== SelectKBest Feature Selection ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22976\\1768359920.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_normalized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mkbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mX_tr_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkbest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_tr_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1362\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \"\"\"\n\u001b[0;32m    560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m             X, y = validate_data(\n\u001b[0m\u001b[0;32m    564\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2971\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2972\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1369\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m                 raise ValueError(\n\u001b[0;32m   1056\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\research\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2164\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2167\u001b[0m             \u001b[1;31m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2168\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2170\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'M'"
     ]
    }
   ],
   "source": [
    "# RandomForest configuration sweep: Original, Normalized, SelectKBest, RFECV, PCA, SMOTE pipelines\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the random state\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Load the training and validation sets\n",
    "import joblib\n",
    "import os\n",
    "processed_data_dir = 'Analysis/processed_data'\n",
    "\n",
    "X_train = joblib.load(os.path.join(processed_data_dir, 'X_train.joblib'))\n",
    "X_val = joblib.load(os.path.join(processed_data_dir, 'X_val.joblib'))\n",
    "y_train = joblib.load(os.path.join(processed_data_dir, 'y_train.joblib'))\n",
    "y_val = joblib.load(os.path.join(processed_data_dir, 'y_val.joblib'))\n",
    "\n",
    "# Define a standard preprocessor for reuse\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Clear previous stored results\n",
    "try:\n",
    "    clear_results()\n",
    "except Exception:\n",
    "    try:\n",
    "        clearResults()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"\\n=== START: RandomForest configuration sweep ===\")\n",
    "\n",
    "# -------------------------\n",
    "# 1) Prepare configurations\n",
    "# -------------------------\n",
    "configurations = []   # tuples: (name, kind, X_train_ready, X_val_ready / or pipeline)\n",
    "# kind == 'array' -> X arrays ready\n",
    "# kind == 'pipeline' -> pipeline object that expects raw DataFrame X\n",
    "\n",
    "# Original Data (raw)\n",
    "configurations.append(('Original Data', 'array', X_train, X_val))\n",
    "\n",
    "# Normalized Data (MinMax)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_numeric = X_train[numeric_features]\n",
    "X_val_numeric = X_val[numeric_features]\n",
    "\n",
    "X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train_numeric), columns=X_train_numeric.columns, index=X_train_numeric.index)\n",
    "X_val_normalized = pd.DataFrame(scaler.transform(X_val_numeric), columns=X_val_numeric.columns, index=X_val_numeric.index)\n",
    "\n",
    "X_train_normalized = pd.concat([X_train_normalized, X_train.drop(numeric_features, axis=1)], axis=1)\n",
    "X_val_normalized = pd.concat([X_val_normalized, X_val.drop(numeric_features, axis=1)], axis=1)\n",
    "\n",
    "configurations.append(('Normalized Data', 'array', X_train_normalized, X_val_normalized))\n",
    "\n",
    "# SelectKBest (on numeric data only) -> find optimal k with RF cross-val\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "X_train_normalized_numeric = X_train_normalized[numeric_features]\n",
    "X_val_normalized_numeric = X_val_normalized[numeric_features]\n",
    "\n",
    "n_features = X_train_normalized_numeric.shape[1]\n",
    "scores = []\n",
    "for k in range(1, n_features + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_tr_k = kbest.fit_transform(X_train_normalized_numeric, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=RANDOM_STATE), X_tr_k, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = int(np.argmax(scores) + 1)\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = pd.DataFrame(kbest.fit_transform(X_train_normalized_numeric, y_train), columns=X_train_normalized_numeric.columns[kbest.get_support()])\n",
    "X_val_kbest = pd.DataFrame(kbest.transform(X_val_normalized_numeric), columns=X_train_kbest.columns)\n",
    "configurations.append(('SelectKBest', 'array', X_train_kbest, X_val_kbest))\n",
    "\n",
    "# RFECV on the SelectKBest-transformed data (numeric only)\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = pd.DataFrame(rfe.fit_transform(X_train_kbest, y_train), columns=X_train_kbest.columns[rfe.get_support()])\n",
    "X_val_rfe = pd.DataFrame(rfe.transform(X_val_kbest), columns=X_train_rfe.columns)\n",
    "configurations.append(('RFECV', 'array', X_train_rfe, X_val_rfe))\n",
    "\n",
    "# PCA on the RFECV-reduced data (numeric only, default 95% cumulative variance)\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "desired_variance = 0.95   # change to 0.90 or 0.99 if needed\n",
    "pca_full = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "n_components = int(np.argmax(cumulative_variance >= desired_variance) + 1)\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=RANDOM_STATE)\n",
    "X_train_pca = pd.DataFrame(pca.fit_transform(X_train_rfe), index=X_train_rfe.index)\n",
    "X_val_pca = pd.DataFrame(pca.transform(X_val_rfe), index=X_val_rfe.index)\n",
    "configurations.append(('PCA', 'array', X_train_pca, X_val_pca))\n",
    "\n",
    "# SMOTE + StandardScaler pipeline (will be treated as 'pipeline')\n",
    "pipeline_smote_scaler = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),            # uses notebook preprocessor\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('model', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "configurations.append(('SMOTE + StandardScaler', 'pipeline', pipeline_smote_scaler, None))\n",
    "\n",
    "# SMOTE + GridSearchCV pipeline (we'll grid search the pipeline)\n",
    "pipeline_smote_grid = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "    ('model', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "configurations.append(('SMOTE + GridSearchCV', 'pipeline', pipeline_smote_grid, None))\n",
    "\n",
    "# -------------------------\n",
    "# Hyperparameter grids\n",
    "# -------------------------\n",
    "param_grid_array = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [10, 20, 50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "# pipeline keys prefixed with model__\n",
    "param_grid_pipeline = {f\"model__{k}\": v for k, v in param_grid_array.items()}\n",
    "\n",
    "# CV folds\n",
    "cv_folds = 10\n",
    "\n",
    "# safe roc auc helper\n",
    "def safe_roc_auc(y_true, y_proba):\n",
    "    try:\n",
    "        if isinstance(y_proba, np.ndarray) and y_proba.shape[1] == 2:\n",
    "            return metrics.roc_auc_score(y_true, y_proba[:, 1])\n",
    "        else:\n",
    "            return metrics.roc_auc_score(pd.get_dummies(y_true), y_proba, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# -------------------------\n",
    "# Run GridSearchCV per configuration\n",
    "# -------------------------\n",
    "for name, kind, X_tr_cfg, X_val_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    if kind == 'pipeline':\n",
    "        pipeline = X_tr_cfg\n",
    "        grid = GridSearchCV(pipeline, param_grid_pipeline, cv=cv_folds, n_jobs=-1, verbose=2)\n",
    "        # Fit on original raw training data (pipeline handles preprocess & SMOTE)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best = grid.best_estimator_\n",
    "        y_train_pred = best.predict(X_train)\n",
    "        y_val_pred = best.predict(X_val)\n",
    "        y_train_proba = best.predict_proba(X_train)\n",
    "        y_val_proba = best.predict_proba(X_val)\n",
    "    else:\n",
    "        X_train_arr = X_tr_cfg\n",
    "        X_val_arr = X_val_cfg\n",
    "        grid = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE), param_grid_array, cv=cv_folds, n_jobs=-1, verbose=2)\n",
    "        grid.fit(X_train_arr, y_train)\n",
    "        best = grid.best_estimator_\n",
    "        y_train_pred = best.predict(X_train_arr)\n",
    "        y_val_pred = best.predict(X_val_arr)\n",
    "        y_train_proba = best.predict_proba(X_train_arr)\n",
    "        y_val_proba = best.predict_proba(X_val_arr)\n",
    "\n",
    "    # Build metrics dict and print table (6-decimal floats to match examples)\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train, y_train_pred),\n",
    "            metrics.accuracy_score(y_val, y_val_pred),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.f1_score(y_val, y_val_pred, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train, y_train_pred, average='macro'),\n",
    "            metrics.recall_score(y_val, y_val_pred, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train, y_train_pred, average='macro', zero_division=0),\n",
    "            metrics.precision_score(y_val, y_val_pred, average='macro', zero_division=0),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            safe_roc_auc(y_train, y_train_proba),\n",
    "            safe_roc_auc(y_val, y_val_proba),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    pd.options.display.float_format = '{:.6f}'.format\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    # Store test metrics using your storage API (camelCase alias)\n",
    "    test_row = df_metrics[df_metrics['Dataset'] == 'Test'].iloc[0]\n",
    "    try:\n",
    "        storeResults(\n",
    "            'Random Forest',\n",
    "            name,\n",
    "            float(test_row['Accuracy']),\n",
    "            float(test_row['F1 Score']),\n",
    "            float(test_row['Recall']),\n",
    "            float(test_row['Precision']),\n",
    "            float(test_row['AUC-ROC'])\n",
    "        )\n",
    "    except Exception:\n",
    "        # fallback to snake_case\n",
    "        store_results(\n",
    "            'Random Forest',\n",
    "            name,\n",
    "            float(test_row['Accuracy']),\n",
    "            float(test_row['F1 Score']),\n",
    "            float(test_row['Recall']),\n",
    "            float(test_row['Precision']),\n",
    "            float(test_row['AUC-ROC'])\n",
    "        )\n",
    "\n",
    "    print(\"\\nBest hyperparameters found by GridSearchCV:\")\n",
    "    try:\n",
    "        print(grid.best_params_)\n",
    "    except Exception:\n",
    "        print(\"best_params_ not available for this run.\")\n",
    "\n",
    "print(\"\\n=== RandomForest sweep complete ===\")\n",
    "\n",
    "# Save & display aggregated results then plot\n",
    "try:\n",
    "    displayAndSaveResults('random_forest_sweep')\n",
    "except Exception:\n",
    "    display_and_save_results('random_forest_sweep')\n",
    "\n",
    "try:\n",
    "    plotModelComparison()\n",
    "except Exception:\n",
    "    plot_model_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f15b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e83f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b98f560a",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fe52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Store different configurations\u001b[39;00m\n\u001b[0;32m      4\u001b[0m configurations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m configurations\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Data\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train, \u001b[43mX_test\u001b[49m, y_train))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Step 2: Normalize the data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Written by Hasib\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c96ed2",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5784085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 17\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 17\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 16\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.979634\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346  0.97968\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.988670 0.979167   0.998847 1.000000\n",
      "    Test  0.943128  0.682828 0.579545   0.980392 0.942089\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Written by Hasib\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6a460",
   "metadata": {},
   "source": [
    "### Random Forest with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfd1a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 17\n",
      "\n",
      "=== RFECV Feature Selection with Random Forest ===\n",
      "Optimal number of features selected by RFECV: 17\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 17\n",
      "\n",
      "=== Random Forest Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Random Forest with Original Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.979634\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.933649  0.599386 0.530303   0.977346  0.97968\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Running Random Forest with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with RFECV configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.962434\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Running Random Forest with PCA configuration...\n",
      "Fitting 10 folds for each of 128 candidates, totalling 1280 fits\n",
      "\n",
      "Random Forest Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.943128  0.688312 0.590909   0.980392 0.963099\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Random Forest classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(RandomForestClassifier(random_state=42), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Random Forest ===\")\n",
    "rf_estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(estimator=rf_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Random Forest + GridSearchCV\n",
    "print(\"\\n=== Random Forest Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200,300,400],\n",
    "    'max_depth': [10,20,50, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Random Forest with {name} configuration...\")\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    rf.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_rf = rf.predict(X_train_cfg)\n",
    "    y_test_rf = rf.predict(X_test_cfg)\n",
    "    y_train_rf_proba = rf.predict_proba(X_train_cfg)\n",
    "    y_test_rf_proba = rf.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_rf),\n",
    "            metrics.accuracy_score(y_test, y_test_rf),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_rf, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_rf_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nRandom Forest Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_rf_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Random Forest 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_rf),\n",
    "        metrics.f1_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_rf, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_rf, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16942ac3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c0f7b8",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9fe6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 14\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 14\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 12\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.848374 0.765152   0.988275 0.990586\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.957346  0.790443 0.693182   0.985075  0.98958\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987328 0.989005   0.986088 0.999959\n",
      "    Test  0.952607  0.769274 0.702809   0.937381 0.942574\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987201 0.985532   0.989320 0.999959\n",
      "    Test  0.952607  0.769274 0.702809   0.937381 0.953654\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987201 0.985532   0.989320 0.999959\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.923748\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15, 21],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9909e6",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1894f6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 16\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 16\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 15\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000   1.00000 1.000000    1.00000 1.000000\n",
      "    Test  0.947867   0.74708 0.661143    0.91675 0.986373\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.983715\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987328 0.989005   0.986088 0.999959\n",
      "    Test  0.952607  0.759061 0.662879   0.983498 0.954009\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987201 0.985532   0.989320 0.999959\n",
      "    Test  0.962085  0.818235 0.723485   0.986667 0.967974\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987201 0.985532   0.989320 0.999959\n",
      "    Test  0.938389  0.647204 0.560606   0.978862 0.911336\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15, 21],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12584b8b",
   "metadata": {},
   "source": [
    "### Gradient Boosting with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c47df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 14\n",
      "\n",
      "=== RFECV Feature Selection with Gradient Boosting ===\n",
      "Optimal number of features selected by RFECV: 14\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 14\n",
      "\n",
      "=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Gradient Boosting with Original Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.962085  0.820578 0.734848   0.986667 0.990144\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.962085  0.820578 0.734848   0.986667  0.98729\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.957346  0.800661 0.733112   0.938981 0.957123\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with RFECV configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.947867  0.733527 0.672506   0.935797 0.956817\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Running Gradient Boosting with PCA configuration...\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "\n",
      "Gradient Boosting Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.938389  0.634384 0.571970   0.978862 0.951643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Gradient Boosting classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(GradientBoostingClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Gradient Boosting ===\")\n",
    "gbc_estimator = GradientBoostingClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=gbc_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=gbc_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: Gradient Boosting + GridSearchCV\n",
    "print(\"\\n=== Gradient Boosting Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [100, 200,500],\n",
    "    'max_depth': [3, 5,7,9,15, 21],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'subsample': [0.8],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Gradient Boosting with {name} configuration...\")\n",
    "    gbc = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "    gbc.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_gbc = gbc.predict(X_train_cfg)\n",
    "    y_test_gbc = gbc.predict(X_test_cfg)\n",
    "    y_train_gbc_proba = gbc.predict_proba(X_train_cfg)\n",
    "    y_test_gbc_proba = gbc.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_gbc),\n",
    "            metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_gbc, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_gbc_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nGradient Boosting Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_gbc_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Gradient Boosting 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_gbc),\n",
    "        metrics.f1_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_gbc, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_gbc, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(gbc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06f7fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8f838",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb4da461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 25\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 11\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 10\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.860668 0.805082   0.942229 0.992096\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.860668 0.805082   0.942229 0.992096\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.962085  0.818235 0.723485   0.986667  0.98906\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.984177  0.943348 0.935185   0.952095 0.998158\n",
      "    Test  0.947867  0.747080 0.661143   0.916750 0.967564\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.938389  0.693736 0.629104   0.842869 0.961022\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac54dd",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2931c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 25\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 11\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 10\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.957346  0.790443 0.693182   0.985075 0.984545\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.957346  0.790443 0.693182   0.985075 0.984545\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.962085  0.818235 0.723485   0.986667  0.98906\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training   1.00000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test   0.92891  0.698926 0.654198   0.760857 0.942082\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.853261 0.793718   0.942229 0.970545\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad91dc7",
   "metadata": {},
   "source": [
    "### Adaboost with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c96e1c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 25\n",
      "\n",
      "=== RFECV Feature Selection with AdaBoost ===\n",
      "Optimal number of features selected by RFECV: 11\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 11\n",
      "\n",
      "=== AdaBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running AdaBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.957346  0.804293 0.721749   0.938981 0.990977\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000  1.00000\n",
      "    Test  0.962085  0.818235 0.723485   0.986667  0.98906\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 200}\n",
      "\n",
      "Running AdaBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.966825  0.858663 0.793718   0.948181 0.989472\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training  1.000000   1.00000 1.00000   1.000000 1.000000\n",
      "    Test  0.938389   0.71114 0.65767   0.821345 0.941128\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=5), 'learning_rate': 1, 'n_estimators': 100}\n",
      "\n",
      "Running AdaBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "\n",
      "AdaBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score  Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.00000   1.000000 1.000000\n",
      "    Test  0.947867  0.775759 0.72964   0.843606 0.962821\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'algorithm': 'SAMME', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, AdaBoost classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(AdaBoostClassifier(), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with AdaBoost ===\")\n",
    "ab_estimator = AdaBoostClassifier()\n",
    "\n",
    "rfecv = RFECV(estimator=ab_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=ab_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: AdaBoost + GridSearchCV\n",
    "print(\"\\n=== AdaBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'estimator': [DecisionTreeClassifier(max_depth=d) for d in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning AdaBoost with {name} configuration...\")\n",
    "    ab = GridSearchCV(\n",
    "        AdaBoostClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    ab.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_ab = ab.predict(X_train_cfg)\n",
    "    y_test_ab = ab.predict(X_test_cfg)\n",
    "    y_train_ab_proba = ab.predict_proba(X_train_cfg)\n",
    "    y_test_ab_proba = ab.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_ab),\n",
    "            metrics.accuracy_score(y_test, y_test_ab),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_ab, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_ab_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nAdaBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_ab_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'AdaBoost 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_ab),\n",
    "        metrics.f1_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_ab, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_ab, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911a9a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76533d1",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90fa3173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 15\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 15\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 13\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.973101  0.883080 0.818866   0.975103 0.991660\n",
      "    Test  0.943128  0.682207 0.602273   0.980392 0.949287\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17717807",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4be3de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 15\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 15\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 14\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.969937  0.869930 0.807870   0.958666 0.987737\n",
      "    Test  0.938389  0.674871 0.640467   0.898425 0.921033\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4191db",
   "metadata": {},
   "source": [
    "### XGBoost with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "612e7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 15\n",
      "\n",
      "=== RFECV Feature Selection with XGBoost ===\n",
      "Optimal number of features selected by RFECV: 15\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 15\n",
      "\n",
      "=== XGBoost Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running XGBoost with Original Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  1.000000  1.000000 1.000000   1.000000 1.000000\n",
      "    Test  0.952607  0.755429 0.651515   0.983498 0.986044\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with RFECV configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.996835  0.987039 0.975694   0.998847 0.999959\n",
      "    Test  0.952607  0.753445 0.674242   0.983498 0.956643\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Running XGBoost with PCA configuration...\n",
      "Fitting 10 folds for each of 162 candidates, totalling 1620 fits\n",
      "\n",
      "XGBoost Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.981013  0.922644 0.887731   0.966466 0.997345\n",
      "    Test  0.947867  0.723318 0.632576   0.981938 0.961429\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, XGBoost classification with preprocessing and result logging\n",
    "\n",
    "\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'), \n",
    "                            X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with XGBoost ===\")\n",
    "xgb_estimator = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "rfecv = RFECV(estimator=xgb_estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=xgb_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: XGBoost + GridSearchCV\n",
    "print(\"\\n=== XGBoost Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning XGBoost with {name} configuration...\")\n",
    "    xgb = GridSearchCV(\n",
    "        XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_xgb = xgb.predict(X_train_cfg)\n",
    "    y_test_xgb = xgb.predict(X_test_cfg)\n",
    "    y_train_xgb_proba = xgb.predict_proba(X_train_cfg)\n",
    "    y_test_xgb_proba = xgb.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_xgb),\n",
    "            metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_xgb, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_xgb_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nXGBoost Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_xgb_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'XGBoost 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_xgb),\n",
    "        metrics.f1_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_xgb, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_xgb, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78501f2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0264b",
   "metadata": {},
   "source": [
    "### Bagging classification with PCA 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "972b06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 22\n",
      "\n",
      "=== RFECV Feature Selection with Bagging ===\n",
      "Optimal number of features selected by RFECV: 1\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 90.0% variance: 1\n",
      "\n",
      "=== Bagging Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Bagging with Original Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.981013  0.916868 0.857639   0.993197 0.999923\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.954901\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 0.8, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.981013  0.916868 0.857639   0.993197 0.999849\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.949225\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.979430  0.907726 0.843750   0.992643 0.999750\n",
      "    Test  0.943128  0.688312 0.590909   0.980392 0.937465\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 200}\n",
      "\n",
      "Running Bagging with RFECV configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.705290\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.709804\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 0.6, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with PCA configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.706551\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.713093\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 0.6, 'max_samples': 0.6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "# Use single DecisionTreeClassifier for RFECV to enable feature_importances_\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=tree_estimator,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=tree_estimator, n_features_to_select=rfecv.n_features_)\n",
    "\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.90\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'estimator': [ \n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging 90',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b7511",
   "metadata": {},
   "source": [
    "### Bagging classification with PCA 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f14f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 10\n",
      "\n",
      "=== RFECV Feature Selection with Bagging ===\n",
      "Optimal number of features selected by RFECV: 2\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 95.0% variance: 2\n",
      "\n",
      "=== Bagging Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Bagging with Original Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.958861  0.794992 0.704861   0.985604 0.998462\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.967648\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5, min_samples_split=5), 'max_features': 0.6, 'max_samples': 1.0, 'n_estimators': 150}\n",
      "\n",
      "Running Bagging with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.962025  0.815719 0.725694   0.986667 0.998742\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.949401\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5, min_samples_split=5), 'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.958861  0.800964 0.711227   0.965278 0.996363\n",
      "    Test  0.943128  0.688312 0.590909   0.980392 0.809759\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 0.8, 'n_estimators': 200}\n",
      "\n",
      "Running Bagging with RFECV configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.920886  0.516274 0.509838   0.526580 0.848390\n",
      "    Test  0.872038  0.347470 0.359375   0.336816 0.702292\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5, min_samples_split=5), 'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with PCA configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.920886  0.516274 0.509838   0.526580 0.843728\n",
      "    Test  0.872038  0.347470 0.359375   0.336816 0.707771\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5, min_samples_split=5), 'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "# Use single DecisionTreeClassifier for RFECV to enable feature_importances_\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=tree_estimator,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=tree_estimator, n_features_to_select=rfecv.n_features_)\n",
    "\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.95\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'estimator': [ \n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging 95',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d444d",
   "metadata": {},
   "source": [
    "### Bagging classification with PCA 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "066459e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SelectKBest Feature Selection ===\n",
      "Optimal number of features to select using SelectKBest: 13\n",
      "\n",
      "=== RFECV Feature Selection with Bagging ===\n",
      "Optimal number of features selected by RFECV: 1\n",
      "\n",
      "=== PCA Dimensionality Reduction ===\n",
      "Number of components that explain 99.0% variance: 1\n",
      "\n",
      "=== Bagging Model Performance with Hyperparameter Tuning ===\n",
      "\n",
      "Running Bagging with Original Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.957278  0.783941 0.694444   0.985075 0.998444\n",
      "    Test  0.928910  0.558176 0.488636   0.975845 0.927392\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5, min_samples_split=5), 'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with Normalized Data configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.952532  0.751826 0.656250   0.983498 0.999227\n",
      "    Test  0.933649  0.599386 0.530303   0.977346 0.960423\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 0.6, 'n_estimators': 150}\n",
      "\n",
      "Running Bagging with SelectKBest configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.974684  0.888283 0.822338   0.977637 0.998922\n",
      "    Test  0.943128  0.688312 0.590909   0.980392 0.886902\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(min_samples_split=10), 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 150}\n",
      "\n",
      "Running Bagging with RFECV configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.733710\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.712548\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 0.6, 'max_samples': 0.6, 'n_estimators': 100}\n",
      "\n",
      "Running Bagging with PCA configuration...\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "\n",
      "Bagging Model Performance Metrics\n",
      " Dataset  Accuracy  F1 Score   Recall  Precision  AUC-ROC\n",
      "Training  0.911392  0.317881 0.333333   0.303797 0.733710\n",
      "    Test  0.909953  0.317618 0.333333   0.303318 0.712548\n",
      "Best hyperparameters found by GridSearchCV:\n",
      "{'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 0.6, 'max_samples': 0.6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2025-07-07, Bagging classification with preprocessing and result logging\n",
    "\n",
    "# Store different configurations\n",
    "configurations = []\n",
    "configurations.append(('Original Data', X_train, X_test, y_train))\n",
    "\n",
    "# Step 2: Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "configurations.append(('Normalized Data', X_train_normalized, X_test_normalized, y_train))\n",
    "\n",
    "# Step 3.1: SelectKBest\n",
    "print(\"\\n=== SelectKBest Feature Selection ===\")\n",
    "scores = []\n",
    "for k in range(1, X_train.shape[1] + 1):\n",
    "    kbest = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "    score = cross_val_score(BaggingClassifier(estimator=DecisionTreeClassifier()), X_train_kbest, y_train, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "optimal_k = scores.index(max(scores)) + 1\n",
    "print(f\"Optimal number of features to select using SelectKBest: {optimal_k}\")\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=optimal_k)\n",
    "X_train_kbest = kbest.fit_transform(X_train_normalized, y_train)\n",
    "X_test_kbest = kbest.transform(X_test_normalized)\n",
    "selected_features_kbest = X.columns[kbest.get_support()]\n",
    "configurations.append(('SelectKBest', X_train_kbest, X_test_kbest, y_train))\n",
    "\n",
    "# Step 3.2: RFECV\n",
    "print(\"\\n=== RFECV Feature Selection with Bagging ===\")\n",
    "# Use single DecisionTreeClassifier for RFECV to enable feature_importances_\n",
    "tree_estimator = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=tree_estimator,\n",
    "    step=1,\n",
    "    cv=StratifiedKFold(5),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfecv.fit(X_train_kbest, y_train)\n",
    "print(f\"Optimal number of features selected by RFECV: {rfecv.n_features_}\")\n",
    "\n",
    "rfe = RFE(estimator=tree_estimator, n_features_to_select=rfecv.n_features_)\n",
    "X_train_rfe = rfe.fit_transform(X_train_kbest, y_train)\n",
    "X_test_rfe = rfe.transform(X_test_kbest)\n",
    "selected_features_rfe = selected_features_kbest[rfe.get_support()]\n",
    "configurations.append(('RFECV', X_train_rfe, X_test_rfe, y_train))\n",
    "\n",
    "# Step 3.3: PCA\n",
    "print(\"\\n=== PCA Dimensionality Reduction ===\")\n",
    "pca = PCA().fit(X_train_rfe)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "desired_variance = 0.99\n",
    "n_components = np.argmax(cumulative_variance >= desired_variance) + 1\n",
    "print(f'Number of components that explain {desired_variance * 100}% variance: {n_components}')\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_rfe)\n",
    "X_test_pca = pca.transform(X_test_rfe)\n",
    "configurations.append(('PCA', X_train_pca, X_test_pca, y_train))\n",
    "\n",
    "# Step 4: BaggingClassifier + GridSearchCV\n",
    "print(\"\\n=== Bagging Model Performance with Hyperparameter Tuning ===\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "    'bootstrap': [True],\n",
    "    'bootstrap_features': [False],\n",
    "    'estimator': [ \n",
    "        DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "        DecisionTreeClassifier(max_depth=5, min_samples_split=5),\n",
    "        DecisionTreeClassifier(max_depth=None, min_samples_split=10)\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "for name, X_train_cfg, X_test_cfg, y_train_cfg in configurations:\n",
    "    print(f\"\\nRunning Bagging with {name} configuration...\")\n",
    "    bag = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        param_grid,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    bag.fit(X_train_cfg, y_train_cfg)\n",
    "\n",
    "    y_train_bag = bag.predict(X_train_cfg)\n",
    "    y_test_bag = bag.predict(X_test_cfg)\n",
    "    y_train_bag_proba = bag.predict_proba(X_train_cfg)\n",
    "    y_test_bag_proba = bag.predict_proba(X_test_cfg)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Accuracy\": [\n",
    "            metrics.accuracy_score(y_train_cfg, y_train_bag),\n",
    "            metrics.accuracy_score(y_test, y_test_bag),\n",
    "        ],\n",
    "        \"F1 Score\": [\n",
    "            metrics.f1_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            metrics.recall_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            metrics.precision_score(y_train_cfg, y_train_bag, average='macro'),\n",
    "            metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        ],\n",
    "        \"AUC-ROC\": [\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_train_cfg), y_train_bag_proba, multi_class='ovr', average='macro'),\n",
    "            metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro'),\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(\"\\nBagging Model Performance Metrics\")\n",
    "    print(df_metrics.to_string(index=False))\n",
    "\n",
    "    auc_score = metrics.roc_auc_score(pd.get_dummies(y_test), y_test_bag_proba, multi_class='ovr', average='macro')\n",
    "    storeResults(\n",
    "        'Bagging 99',\n",
    "        name,\n",
    "        metrics.accuracy_score(y_test, y_test_bag),\n",
    "        metrics.f1_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.recall_score(y_test, y_test_bag, average='macro'),\n",
    "        metrics.precision_score(y_test, y_test_bag, average='macro'),\n",
    "        auc_score\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found by GridSearchCV:\")\n",
    "    print(bag.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd3688",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cc80be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "MODEL PERFORMANCE RESULTS\n",
      "====================================================================================================\n",
      "                 ML Model   Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "Support Vector Machine 90   Original Data  98.104%  92.171% 86.742%   99.320% 99.754%\n",
      "Support Vector Machine 90 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.692%\n",
      "Support Vector Machine 90     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.664%\n",
      "Support Vector Machine 90           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 90             PCA  99.052%  96.494% 93.939%   99.656% 99.982%\n",
      "Support Vector Machine 95   Original Data  98.104%  92.171% 86.742%   99.320% 99.745%\n",
      "Support Vector Machine 95 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.710%\n",
      "Support Vector Machine 95     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 95           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 95             PCA  98.578%  94.186% 89.773%   99.487% 99.644%\n",
      "Support Vector Machine 99   Original Data  98.104%  92.171% 86.742%   99.320% 99.653%\n",
      "Support Vector Machine 99 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.692%\n",
      "Support Vector Machine 99     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 99           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 99             PCA  98.104%  93.083% 92.456%   94.097% 99.872%\n",
      "         Random Forest 90   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 90 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "         Random Forest 90     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 90           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 90             PCA  94.313%  68.831% 59.091%   98.039% 94.508%\n",
      "         Random Forest 95   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 95 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "         Random Forest 95     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 95           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 95             PCA  94.313%  68.283% 57.954%   98.039% 94.209%\n",
      "         Random Forest 99   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 99 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "         Random Forest 99     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 99           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 99             PCA  94.313%  68.831% 59.091%   98.039% 96.310%\n",
      "     Gradient Boosting 90   Original Data  96.683%  84.837% 76.515%   98.828% 99.059%\n",
      "     Gradient Boosting 90 Normalized Data  95.735%  79.044% 69.318%   98.508% 98.958%\n",
      "     Gradient Boosting 90     SelectKBest  95.261%  76.927% 70.281%   93.738% 94.257%\n",
      "     Gradient Boosting 90           RFECV  95.261%  76.927% 70.281%   93.738% 95.365%\n",
      "     Gradient Boosting 90             PCA  93.365%  59.939% 53.030%   97.735% 92.375%\n",
      "     Gradient Boosting 95   Original Data  94.787%  74.708% 66.114%   91.675% 98.637%\n",
      "     Gradient Boosting 95 Normalized Data  94.787%  72.332% 63.258%   98.194% 98.371%\n",
      "     Gradient Boosting 95     SelectKBest  95.261%  75.906% 66.288%   98.350% 95.401%\n",
      "     Gradient Boosting 95           RFECV  96.209%  81.824% 72.349%   98.667% 96.797%\n",
      "     Gradient Boosting 95             PCA  93.839%  64.720% 56.061%   97.886% 91.134%\n",
      "     Gradient Boosting 99   Original Data  96.209%  82.058% 73.485%   98.667% 99.014%\n",
      "     Gradient Boosting 99 Normalized Data  96.209%  82.058% 73.485%   98.667% 98.729%\n",
      "     Gradient Boosting 99     SelectKBest  95.735%  80.066% 73.311%   93.898% 95.712%\n",
      "     Gradient Boosting 99           RFECV  94.787%  73.353% 67.251%   93.580% 95.682%\n",
      "     Gradient Boosting 99             PCA  93.839%  63.438% 57.197%   97.886% 95.164%\n",
      "              AdaBoost 90   Original Data  96.683%  86.067% 80.508%   94.223% 99.210%\n",
      "              AdaBoost 90 Normalized Data  96.683%  86.067% 80.508%   94.223% 99.210%\n",
      "              AdaBoost 90     SelectKBest  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 90           RFECV  94.787%  74.708% 66.114%   91.675% 96.756%\n",
      "              AdaBoost 90             PCA  93.839%  69.374% 62.910%   84.287% 96.102%\n",
      "              AdaBoost 95   Original Data  95.735%  79.044% 69.318%   98.508% 98.454%\n",
      "              AdaBoost 95 Normalized Data  95.735%  79.044% 69.318%   98.508% 98.454%\n",
      "              AdaBoost 95     SelectKBest  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 95           RFECV  92.891%  69.893% 65.420%   76.086% 94.208%\n",
      "              AdaBoost 95             PCA  96.683%  85.326% 79.372%   94.223% 97.055%\n",
      "              AdaBoost 99   Original Data  95.735%  80.429% 72.175%   93.898% 99.098%\n",
      "              AdaBoost 99 Normalized Data  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 99     SelectKBest  96.683%  85.866% 79.372%   94.818% 98.947%\n",
      "              AdaBoost 99           RFECV  93.839%  71.114% 65.767%   82.135% 94.113%\n",
      "              AdaBoost 99             PCA  94.787%  77.576% 72.964%   84.361% 96.282%\n",
      "               XGBoost 90   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 90 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 90     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 90           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 90             PCA  94.313%  68.221% 60.227%   98.039% 94.929%\n",
      "               XGBoost 95   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 95 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 95     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 95           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 95             PCA  93.839%  67.487% 64.047%   89.843% 92.103%\n",
      "               XGBoost 99   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 99 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 99     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 99           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 99             PCA  94.787%  72.332% 63.258%   98.194% 96.143%\n",
      "               Bagging 90   Original Data  93.365%  59.939% 53.030%   97.735% 95.490%\n",
      "               Bagging 90 Normalized Data  93.365%  59.939% 53.030%   97.735% 94.922%\n",
      "               Bagging 90     SelectKBest  94.313%  68.831% 59.091%   98.039% 93.746%\n",
      "               Bagging 90           RFECV  90.995%  31.762% 33.333%   30.332% 70.980%\n",
      "               Bagging 90             PCA  90.995%  31.762% 33.333%   30.332% 71.309%\n",
      "               Bagging 95   Original Data  93.365%  59.939% 53.030%   97.735% 96.765%\n",
      "               Bagging 95 Normalized Data  93.365%  59.939% 53.030%   97.735% 94.940%\n",
      "               Bagging 95     SelectKBest  94.313%  68.831% 59.091%   98.039% 80.976%\n",
      "               Bagging 95           RFECV  87.204%  34.747% 35.938%   33.682% 70.229%\n",
      "               Bagging 95             PCA  87.204%  34.747% 35.938%   33.682% 70.777%\n",
      "               Bagging 99   Original Data  92.891%  55.818% 48.864%   97.584% 92.739%\n",
      "               Bagging 99 Normalized Data  93.365%  59.939% 53.030%   97.735% 96.042%\n",
      "               Bagging 99     SelectKBest  94.313%  68.831% 59.091%   98.039% 88.690%\n",
      "               Bagging 99           RFECV  90.995%  31.762% 33.333%   30.332% 71.255%\n",
      "               Bagging 99             PCA  90.995%  31.762% 33.333%   30.332% 71.255%\n",
      "\n",
      "Results saved to model_results.csv\n",
      "\n",
      "====================================================================================================\n",
      "SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\n",
      "====================================================================================================\n",
      "                 ML Model   Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "Support Vector Machine 90             PCA  99.052%  96.494% 93.939%   99.656% 99.982%\n",
      "Support Vector Machine 95             PCA  98.578%  94.186% 89.773%   99.487% 99.644%\n",
      "Support Vector Machine 99             PCA  98.104%  93.083% 92.456%   94.097% 99.872%\n",
      "Support Vector Machine 90   Original Data  98.104%  92.171% 86.742%   99.320% 99.754%\n",
      "Support Vector Machine 90 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.692%\n",
      "Support Vector Machine 90     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.664%\n",
      "Support Vector Machine 90           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 95   Original Data  98.104%  92.171% 86.742%   99.320% 99.745%\n",
      "Support Vector Machine 95 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.710%\n",
      "Support Vector Machine 95     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 95           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 99   Original Data  98.104%  92.171% 86.742%   99.320% 99.653%\n",
      "Support Vector Machine 99 Normalized Data  98.104%  92.171% 86.742%   99.320% 99.692%\n",
      "Support Vector Machine 99     SelectKBest  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "Support Vector Machine 99           RFECV  98.104%  92.171% 86.742%   99.320% 99.646%\n",
      "              AdaBoost 90   Original Data  96.683%  86.067% 80.508%   94.223% 99.210%\n",
      "              AdaBoost 90 Normalized Data  96.683%  86.067% 80.508%   94.223% 99.210%\n",
      "              AdaBoost 99     SelectKBest  96.683%  85.866% 79.372%   94.818% 98.947%\n",
      "              AdaBoost 95             PCA  96.683%  85.326% 79.372%   94.223% 97.055%\n",
      "     Gradient Boosting 90   Original Data  96.683%  84.837% 76.515%   98.828% 99.059%\n",
      "     Gradient Boosting 99   Original Data  96.209%  82.058% 73.485%   98.667% 99.014%\n",
      "     Gradient Boosting 99 Normalized Data  96.209%  82.058% 73.485%   98.667% 98.729%\n",
      "     Gradient Boosting 95           RFECV  96.209%  81.824% 72.349%   98.667% 96.797%\n",
      "              AdaBoost 90     SelectKBest  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 95     SelectKBest  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 99 Normalized Data  96.209%  81.824% 72.349%   98.667% 98.906%\n",
      "              AdaBoost 99   Original Data  95.735%  80.429% 72.175%   93.898% 99.098%\n",
      "     Gradient Boosting 99     SelectKBest  95.735%  80.066% 73.311%   93.898% 95.712%\n",
      "     Gradient Boosting 90 Normalized Data  95.735%  79.044% 69.318%   98.508% 98.958%\n",
      "              AdaBoost 95   Original Data  95.735%  79.044% 69.318%   98.508% 98.454%\n",
      "              AdaBoost 95 Normalized Data  95.735%  79.044% 69.318%   98.508% 98.454%\n",
      "              AdaBoost 99             PCA  94.787%  77.576% 72.964%   84.361% 96.282%\n",
      "     Gradient Boosting 90     SelectKBest  95.261%  76.927% 70.281%   93.738% 94.257%\n",
      "     Gradient Boosting 90           RFECV  95.261%  76.927% 70.281%   93.738% 95.365%\n",
      "     Gradient Boosting 95     SelectKBest  95.261%  75.906% 66.288%   98.350% 95.401%\n",
      "               XGBoost 90   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 90 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 95   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 95 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 99   Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 99 Normalized Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 90     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 90           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 95     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 95           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 99     SelectKBest  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "               XGBoost 99           RFECV  95.261%  75.344% 67.424%   98.350% 95.664%\n",
      "     Gradient Boosting 95   Original Data  94.787%  74.708% 66.114%   91.675% 98.637%\n",
      "              AdaBoost 90           RFECV  94.787%  74.708% 66.114%   91.675% 96.756%\n",
      "     Gradient Boosting 99           RFECV  94.787%  73.353% 67.251%   93.580% 95.682%\n",
      "         Random Forest 90     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 90           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 95     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 95           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 99     SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 99           RFECV  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "     Gradient Boosting 95 Normalized Data  94.787%  72.332% 63.258%   98.194% 98.371%\n",
      "               XGBoost 99             PCA  94.787%  72.332% 63.258%   98.194% 96.143%\n",
      "              AdaBoost 99           RFECV  93.839%  71.114% 65.767%   82.135% 94.113%\n",
      "              AdaBoost 95           RFECV  92.891%  69.893% 65.420%   76.086% 94.208%\n",
      "              AdaBoost 90             PCA  93.839%  69.374% 62.910%   84.287% 96.102%\n",
      "         Random Forest 90             PCA  94.313%  68.831% 59.091%   98.039% 94.508%\n",
      "         Random Forest 99             PCA  94.313%  68.831% 59.091%   98.039% 96.310%\n",
      "               Bagging 90     SelectKBest  94.313%  68.831% 59.091%   98.039% 93.746%\n",
      "               Bagging 95     SelectKBest  94.313%  68.831% 59.091%   98.039% 80.976%\n",
      "               Bagging 99     SelectKBest  94.313%  68.831% 59.091%   98.039% 88.690%\n",
      "         Random Forest 95             PCA  94.313%  68.283% 57.954%   98.039% 94.209%\n",
      "               XGBoost 90             PCA  94.313%  68.221% 60.227%   98.039% 94.929%\n",
      "               XGBoost 95             PCA  93.839%  67.487% 64.047%   89.843% 92.103%\n",
      "     Gradient Boosting 95             PCA  93.839%  64.720% 56.061%   97.886% 91.134%\n",
      "     Gradient Boosting 99             PCA  93.839%  63.438% 57.197%   97.886% 95.164%\n",
      "         Random Forest 90   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 90 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "         Random Forest 95   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 95 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "         Random Forest 99   Original Data  93.365%  59.939% 53.030%   97.735% 97.963%\n",
      "         Random Forest 99 Normalized Data  93.365%  59.939% 53.030%   97.735% 97.968%\n",
      "     Gradient Boosting 90             PCA  93.365%  59.939% 53.030%   97.735% 92.375%\n",
      "               Bagging 90   Original Data  93.365%  59.939% 53.030%   97.735% 95.490%\n",
      "               Bagging 90 Normalized Data  93.365%  59.939% 53.030%   97.735% 94.922%\n",
      "               Bagging 95   Original Data  93.365%  59.939% 53.030%   97.735% 96.765%\n",
      "               Bagging 95 Normalized Data  93.365%  59.939% 53.030%   97.735% 94.940%\n",
      "               Bagging 99 Normalized Data  93.365%  59.939% 53.030%   97.735% 96.042%\n",
      "               Bagging 99   Original Data  92.891%  55.818% 48.864%   97.584% 92.739%\n",
      "               Bagging 95           RFECV  87.204%  34.747% 35.938%   33.682% 70.229%\n",
      "               Bagging 95             PCA  87.204%  34.747% 35.938%   33.682% 70.777%\n",
      "               Bagging 90           RFECV  90.995%  31.762% 33.333%   30.332% 70.980%\n",
      "               Bagging 90             PCA  90.995%  31.762% 33.333%   30.332% 71.309%\n",
      "               Bagging 99           RFECV  90.995%  31.762% 33.333%   30.332% 71.255%\n",
      "               Bagging 99             PCA  90.995%  31.762% 33.333%   30.332% 71.255%\n",
      "\n",
      "Sorted results saved to sorted_model_results.csv\n",
      "\n",
      "====================================================================================================\n",
      "TOP CONFIGURATION PER MODEL\n",
      "====================================================================================================\n",
      "                 ML Model Configuration Accuracy F1 Score  Recall Precision ROC_AUC\n",
      "              AdaBoost 90 Original Data  96.683%  86.067% 80.508%   94.223% 99.210%\n",
      "              AdaBoost 95           PCA  96.683%  85.326% 79.372%   94.223% 97.055%\n",
      "              AdaBoost 99   SelectKBest  96.683%  85.866% 79.372%   94.818% 98.947%\n",
      "               Bagging 90   SelectKBest  94.313%  68.831% 59.091%   98.039% 93.746%\n",
      "               Bagging 95   SelectKBest  94.313%  68.831% 59.091%   98.039% 80.976%\n",
      "               Bagging 99   SelectKBest  94.313%  68.831% 59.091%   98.039% 88.690%\n",
      "     Gradient Boosting 90 Original Data  96.683%  84.837% 76.515%   98.828% 99.059%\n",
      "     Gradient Boosting 95         RFECV  96.209%  81.824% 72.349%   98.667% 96.797%\n",
      "     Gradient Boosting 99 Original Data  96.209%  82.058% 73.485%   98.667% 99.014%\n",
      "         Random Forest 90   SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 95   SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "         Random Forest 99   SelectKBest  94.787%  72.332% 63.258%   98.194% 96.243%\n",
      "Support Vector Machine 90           PCA  99.052%  96.494% 93.939%   99.656% 99.982%\n",
      "Support Vector Machine 95           PCA  98.578%  94.186% 89.773%   99.487% 99.644%\n",
      "Support Vector Machine 99           PCA  98.104%  93.083% 92.456%   94.097% 99.872%\n",
      "               XGBoost 90 Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 95 Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "               XGBoost 99 Original Data  95.261%  75.543% 65.151%   98.350% 98.604%\n",
      "\n",
      "Top configuration per model saved to top_configurations.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataframe\n",
    "result = pd.DataFrame({\n",
    "    'ML Model': ML_Model,\n",
    "    'Configuration': ML_Config,\n",
    "    'Accuracy': [f\"{acc * 100:.3f}%\" for acc in accuracy],\n",
    "    'F1 Score': [f\"{f1 * 100:.3f}%\" for f1 in f1_score],\n",
    "    'Recall': [f\"{rec * 100:.3f}%\" for rec in recall],\n",
    "    'Precision': [f\"{prec * 100:.3f}%\" for prec in precision],\n",
    "    'ROC_AUC': [f\"{roc * 100:.3f}%\" for roc in auc_roc],\n",
    "})\n",
    "\n",
    "# Remove duplicates based on model and configuration\n",
    "result.drop_duplicates(subset=[\"ML Model\", \"Configuration\"], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL PERFORMANCE RESULTS\")\n",
    "print(\"=\" * 100)\n",
    "print(result.to_string(index=False))\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('results/model_results.csv', index=False)\n",
    "print(\"\\nResults saved to model_results.csv\")\n",
    "\n",
    "# Sort by Accuracy and F1 Score\n",
    "sorted_result = result.sort_values(by=['F1 Score', 'Accuracy'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the sorted result\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SORTED MODEL PERFORMANCE RESULTS (by Accuracy and F1 Score)\")\n",
    "print(\"=\" * 100)\n",
    "print(sorted_result.to_string(index=False))\n",
    "\n",
    "# Save the sorted result\n",
    "sorted_result.to_csv('results/sorted_model_results.csv', index=False)\n",
    "print(\"\\nSorted results saved to sorted_model_results.csv\")\n",
    "\n",
    "# Extract top configuration per ML model\n",
    "top_per_model = sorted_result.groupby('ML Model', as_index=False).first()\n",
    "\n",
    "# Display and save the top configuration table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP CONFIGURATION PER MODEL\")\n",
    "print(\"=\" * 100)\n",
    "print(top_per_model.to_string(index=False))\n",
    "\n",
    "top_per_model.to_csv('results/top_configurations.csv', index=False)\n",
    "print(\"\\nTop configuration per model saved to top_configurations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "720aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read input CSV\n",
    "df = pd.read_csv('results/top_configurations.csv')\n",
    "\n",
    "# Sort by 'Accuracy' column in descending order\n",
    "df_sorted = df.sort_values(by=['F1 Score', 'Accuracy'], ascending=False)\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV\n",
    "df_sorted.to_csv('results/sorted_top_configurations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cf9c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
